\documentclass[11pt]{article}

    \usepackage[breakable]{tcolorbox}
    \usepackage{parskip} % Stop auto-indenting (to mimic markdown behaviour)
    

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % Keep aspect ratio if custom image width or height is specified
    \setkeys{Gin}{keepaspectratio}
    % Maintain compatibility with old templates. Remove in nbconvert 6.0
    \let\Oldincludegraphics\includegraphics
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionFormat{nocaption}{}
    \captionsetup{format=nocaption,aboveskip=0pt,belowskip=0pt}

    \usepackage{float}
    \floatplacement{figure}{H} % forces figures to be placed at the correct location
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro

    \usepackage{iftex}
    \ifPDFTeX
        \usepackage[T1]{fontenc}
        \IfFileExists{alphabeta.sty}{
              \usepackage{alphabeta}
          }{
              \usepackage[mathletters]{ucs}
              \usepackage[utf8x]{inputenc}
          }
    \else
        \usepackage{fontspec}
        \usepackage{unicode-math}
    \fi

    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics
                         % to support a larger range
    \makeatletter % fix for old versions of grffile with XeLaTeX
    \@ifpackagelater{grffile}{2019/11/01}
    {
      % Do nothing on new versions
    }
    {
      \def\Gread@@xetex#1{%
        \IfFileExists{"\Gin@base".bb}%
        {\Gread@eps{\Gin@base.bb}}%
        {\Gread@@xetex@aux#1}%
      }
    }
    \makeatother
    \usepackage[Export]{adjustbox} % Used to constrain images to a maximum size
    \adjustboxset{max size={0.9\linewidth}{0.9\paperheight}}

    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    % The default LaTeX title has an obnoxious amount of whitespace. By default,
    % titling removes some of it. It also provides customization options.
    \usepackage{titling}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage{array}     % table support for pandoc >= 2.11.3
    \usepackage{calc}      % table minipage width calculation for pandoc >= 2.11.1
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    \usepackage{soul}      % strikethrough (\st) support for pandoc >= 3.0.0
    \usepackage{mathrsfs}
    

    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}
    \definecolor{ansi-default-inverse-fg}{HTML}{FFFFFF}
    \definecolor{ansi-default-inverse-bg}{HTML}{000000}

    % common color for the border for error outputs.
    \definecolor{outerrorbackground}{HTML}{FFDFDF}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}

    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \makeatletter
    \newsavebox\pandoc@box
    \newcommand*\pandocbounded[1]{%
      \sbox\pandoc@box{#1}%
      % scaling factors for width and height
      \Gscale@div\@tempa\textheight{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
      \Gscale@div\@tempb\linewidth{\wd\pandoc@box}%
      % select the smaller of both
      \ifdim\@tempb\p@<\@tempa\p@
        \let\@tempa\@tempb
      \fi
      % scaling accordingly (\@tempa < 1)
      \ifdim\@tempa\p@<\p@
        \scalebox{\@tempa}{\usebox\pandoc@box}%
      % scaling not needed, use as it is
      \else
        \usebox{\pandoc@box}%
      \fi
    }
    \makeatother

    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatibility definitions
    \def\gt{>}
    \def\lt{<}
    \let\Oldtex\TeX
    \let\Oldlatex\LaTeX
    \renewcommand{\TeX}{\textrm{\Oldtex}}
    \renewcommand{\LaTeX}{\textrm{\Oldlatex}}
    % Document parameters
    % Document title
    \title{test-new-clue}
    
    
    
    
    
    
    
% Pygments definitions
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\@namedef{PY@tok@w}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\@namedef{PY@tok@c}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cp}{\def\PY@tc##1{\textcolor[rgb]{0.61,0.40,0.00}{##1}}}
\@namedef{PY@tok@k}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kp}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kt}{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\@namedef{PY@tok@o}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@ow}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\@namedef{PY@tok@nb}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@nf}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@nc}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@nn}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@ne}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.80,0.25,0.22}{##1}}}
\@namedef{PY@tok@nv}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@no}{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\@namedef{PY@tok@nl}{\def\PY@tc##1{\textcolor[rgb]{0.46,0.46,0.00}{##1}}}
\@namedef{PY@tok@ni}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.44,0.44,0.44}{##1}}}
\@namedef{PY@tok@na}{\def\PY@tc##1{\textcolor[rgb]{0.41,0.47,0.13}{##1}}}
\@namedef{PY@tok@nt}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@nd}{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\@namedef{PY@tok@s}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sd}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@si}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.64,0.35,0.47}{##1}}}
\@namedef{PY@tok@se}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.36,0.12}{##1}}}
\@namedef{PY@tok@sr}{\def\PY@tc##1{\textcolor[rgb]{0.64,0.35,0.47}{##1}}}
\@namedef{PY@tok@ss}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@sx}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@m}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@gh}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\@namedef{PY@tok@gu}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\@namedef{PY@tok@gd}{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\@namedef{PY@tok@gi}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.52,0.00}{##1}}}
\@namedef{PY@tok@gr}{\def\PY@tc##1{\textcolor[rgb]{0.89,0.00,0.00}{##1}}}
\@namedef{PY@tok@ge}{\let\PY@it=\textit}
\@namedef{PY@tok@gs}{\let\PY@bf=\textbf}
\@namedef{PY@tok@ges}{\let\PY@bf=\textbf\let\PY@it=\textit}
\@namedef{PY@tok@gp}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\@namedef{PY@tok@go}{\def\PY@tc##1{\textcolor[rgb]{0.44,0.44,0.44}{##1}}}
\@namedef{PY@tok@gt}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\@namedef{PY@tok@err}{\def\PY@bc##1{{\setlength{\fboxsep}{\string -\fboxrule}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}}
\@namedef{PY@tok@kc}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kd}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kn}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kr}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@bp}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@fm}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@vc}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vg}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vi}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vm}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@sa}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sb}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sc}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@dl}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@s2}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sh}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@s1}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@mb}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mf}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mh}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mi}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@il}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mo}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@ch}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cm}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cpf}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@c1}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cs}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % For linebreaks inside Verbatim environment from package fancyvrb.
    \makeatletter
        \newbox\Wrappedcontinuationbox
        \newbox\Wrappedvisiblespacebox
        \newcommand*\Wrappedvisiblespace {\textcolor{red}{\textvisiblespace}}
        \newcommand*\Wrappedcontinuationsymbol {\textcolor{red}{\llap{\tiny$\m@th\hookrightarrow$}}}
        \newcommand*\Wrappedcontinuationindent {3ex }
        \newcommand*\Wrappedafterbreak {\kern\Wrappedcontinuationindent\copy\Wrappedcontinuationbox}
        % Take advantage of the already applied Pygments mark-up to insert
        % potential linebreaks for TeX processing.
        %        {, <, #, %, $, ' and ": go to next line.
        %        _, }, ^, &, >, - and ~: stay at end of broken line.
        % Use of \textquotesingle for straight quote.
        \newcommand*\Wrappedbreaksatspecials {%
            \def\PYGZus{\discretionary{\char`\_}{\Wrappedafterbreak}{\char`\_}}%
            \def\PYGZob{\discretionary{}{\Wrappedafterbreak\char`\{}{\char`\{}}%
            \def\PYGZcb{\discretionary{\char`\}}{\Wrappedafterbreak}{\char`\}}}%
            \def\PYGZca{\discretionary{\char`\^}{\Wrappedafterbreak}{\char`\^}}%
            \def\PYGZam{\discretionary{\char`\&}{\Wrappedafterbreak}{\char`\&}}%
            \def\PYGZlt{\discretionary{}{\Wrappedafterbreak\char`\<}{\char`\<}}%
            \def\PYGZgt{\discretionary{\char`\>}{\Wrappedafterbreak}{\char`\>}}%
            \def\PYGZsh{\discretionary{}{\Wrappedafterbreak\char`\#}{\char`\#}}%
            \def\PYGZpc{\discretionary{}{\Wrappedafterbreak\char`\%}{\char`\%}}%
            \def\PYGZdl{\discretionary{}{\Wrappedafterbreak\char`\$}{\char`\$}}%
            \def\PYGZhy{\discretionary{\char`\-}{\Wrappedafterbreak}{\char`\-}}%
            \def\PYGZsq{\discretionary{}{\Wrappedafterbreak\textquotesingle}{\textquotesingle}}%
            \def\PYGZdq{\discretionary{}{\Wrappedafterbreak\char`\"}{\char`\"}}%
            \def\PYGZti{\discretionary{\char`\~}{\Wrappedafterbreak}{\char`\~}}%
        }
        % Some characters . , ; ? ! / are not pygmentized.
        % This macro makes them "active" and they will insert potential linebreaks
        \newcommand*\Wrappedbreaksatpunct {%
            \lccode`\~`\.\lowercase{\def~}{\discretionary{\hbox{\char`\.}}{\Wrappedafterbreak}{\hbox{\char`\.}}}%
            \lccode`\~`\,\lowercase{\def~}{\discretionary{\hbox{\char`\,}}{\Wrappedafterbreak}{\hbox{\char`\,}}}%
            \lccode`\~`\;\lowercase{\def~}{\discretionary{\hbox{\char`\;}}{\Wrappedafterbreak}{\hbox{\char`\;}}}%
            \lccode`\~`\:\lowercase{\def~}{\discretionary{\hbox{\char`\:}}{\Wrappedafterbreak}{\hbox{\char`\:}}}%
            \lccode`\~`\?\lowercase{\def~}{\discretionary{\hbox{\char`\?}}{\Wrappedafterbreak}{\hbox{\char`\?}}}%
            \lccode`\~`\!\lowercase{\def~}{\discretionary{\hbox{\char`\!}}{\Wrappedafterbreak}{\hbox{\char`\!}}}%
            \lccode`\~`\/\lowercase{\def~}{\discretionary{\hbox{\char`\/}}{\Wrappedafterbreak}{\hbox{\char`\/}}}%
            \catcode`\.\active
            \catcode`\,\active
            \catcode`\;\active
            \catcode`\:\active
            \catcode`\?\active
            \catcode`\!\active
            \catcode`\/\active
            \lccode`\~`\~
        }
    \makeatother

    \let\OriginalVerbatim=\Verbatim
    \makeatletter
    \renewcommand{\Verbatim}[1][1]{%
        %\parskip\z@skip
        \sbox\Wrappedcontinuationbox {\Wrappedcontinuationsymbol}%
        \sbox\Wrappedvisiblespacebox {\FV@SetupFont\Wrappedvisiblespace}%
        \def\FancyVerbFormatLine ##1{\hsize\linewidth
            \vtop{\raggedright\hyphenpenalty\z@\exhyphenpenalty\z@
                \doublehyphendemerits\z@\finalhyphendemerits\z@
                \strut ##1\strut}%
        }%
        % If the linebreak is at a space, the latter will be displayed as visible
        % space at end of first line, and a continuation symbol starts next line.
        % Stretch/shrink are however usually zero for typewriter font.
        \def\FV@Space {%
            \nobreak\hskip\z@ plus\fontdimen3\font minus\fontdimen4\font
            \discretionary{\copy\Wrappedvisiblespacebox}{\Wrappedafterbreak}
            {\kern\fontdimen2\font}%
        }%

        % Allow breaks at special characters using \PYG... macros.
        \Wrappedbreaksatspecials
        % Breaks at punctuation characters . , ; ? ! and / need catcode=\active
        \OriginalVerbatim[#1,codes*=\Wrappedbreaksatpunct]%
    }
    \makeatother

    % Exact colors from NB
    \definecolor{incolor}{HTML}{303F9F}
    \definecolor{outcolor}{HTML}{D84315}
    \definecolor{cellborder}{HTML}{CFCFCF}
    \definecolor{cellbackground}{HTML}{F7F7F7}

    % prompt
    \makeatletter
    \newcommand{\boxspacing}{\kern\kvtcb@left@rule\kern\kvtcb@boxsep}
    \makeatother
    \newcommand{\prompt}[4]{
        {\ttfamily\llap{{\color{#2}[#3]:\hspace{3pt}#4}}\vspace{-\baselineskip}}
    }
    

    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

\begin{document}
    
    \maketitle
    
    

    
    \section{New Clue}\label{new-clue}

In this notebook, we'll test the new, simplified CLUE implementation.
We're not using Bayesian Neural Networks here, so the uncertainty is
just the entropy of the classifier.

    \subsection{Setup}\label{setup}

    Import libraries

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{2}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import}\PY{+w}{ }\PY{n+nn}{importlib}
\PY{k+kn}{import}\PY{+w}{ }\PY{n+nn}{MyImplementation}\PY{n+nn}{.}\PY{n+nn}{models}\PY{n+nn}{.}\PY{n+nn}{regene\PYZus{}models}\PY{+w}{ }\PY{k}{as}\PY{+w}{ }\PY{n+nn}{regene\PYZus{}models}
\PY{n}{importlib}\PY{o}{.}\PY{n}{reload}\PY{p}{(}\PY{n}{regene\PYZus{}models}\PY{p}{)}
\PY{k+kn}{import}\PY{+w}{ }\PY{n+nn}{torch}
\PY{k+kn}{import}\PY{+w}{ }\PY{n+nn}{torch}\PY{n+nn}{.}\PY{n+nn}{nn}\PY{+w}{ }\PY{k}{as}\PY{+w}{ }\PY{n+nn}{nn}
\PY{k+kn}{import}\PY{+w}{ }\PY{n+nn}{torch}\PY{n+nn}{.}\PY{n+nn}{optim}\PY{+w}{ }\PY{k}{as}\PY{+w}{ }\PY{n+nn}{optim}
\PY{k+kn}{import}\PY{+w}{ }\PY{n+nn}{torchvision}
\PY{k+kn}{import}\PY{+w}{ }\PY{n+nn}{torchvision}\PY{n+nn}{.}\PY{n+nn}{transforms}\PY{+w}{ }\PY{k}{as}\PY{+w}{ }\PY{n+nn}{transforms}
\PY{k+kn}{import}\PY{+w}{ }\PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot}\PY{+w}{ }\PY{k}{as}\PY{+w}{ }\PY{n+nn}{plt}
\PY{k+kn}{import}\PY{+w}{ }\PY{n+nn}{numpy}\PY{+w}{ }\PY{k}{as}\PY{+w}{ }\PY{n+nn}{np}
\PY{k+kn}{import}\PY{+w}{ }\PY{n+nn}{os}
\PY{k+kn}{import}\PY{+w}{ }\PY{n+nn}{MyImplementation}\PY{n+nn}{.}\PY{n+nn}{clue}\PY{n+nn}{.}\PY{n+nn}{new\PYZus{}CLUE}\PY{+w}{ }\PY{k}{as}\PY{+w}{ }\PY{n+nn}{new\PYZus{}CLUE}
\PY{n}{importlib}\PY{o}{.}\PY{n}{reload}\PY{p}{(}\PY{n}{new\PYZus{}CLUE}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{2}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
<module 'new\_CLUE' from '/Users/conor/Documents/College
terms/College/Thesis/Thesis\_Code\_Minimised/MyImplementation/new\_CLUE.py'>
\end{Verbatim}
\end{tcolorbox}
        
    Set the device

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{3}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{if} \PY{n}{torch}\PY{o}{.}\PY{n}{cuda}\PY{o}{.}\PY{n}{is\PYZus{}available}\PY{p}{(}\PY{p}{)}\PY{p}{:}
    \PY{n}{device} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{device}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{cuda}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{k}{elif} \PY{n}{torch}\PY{o}{.}\PY{n}{backends}\PY{o}{.}\PY{n}{mps}\PY{o}{.}\PY{n}{is\PYZus{}available}\PY{p}{(}\PY{p}{)}\PY{p}{:}
    \PY{n}{device} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{device}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{mps}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{k}{else}\PY{p}{:}
    \PY{n}{device} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{device}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{cpu}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Using device: }\PY{l+s+si}{\PYZob{}}\PY{n}{device}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Using device: mps
    \end{Verbatim}

    Load the Datasets

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{4}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Load the MNIST dataset}
\PY{n}{transform} \PY{o}{=} \PY{n}{transforms}\PY{o}{.}\PY{n}{Compose}\PY{p}{(}\PY{p}{[}\PY{n}{transforms}\PY{o}{.}\PY{n}{ToTensor}\PY{p}{(}\PY{p}{)}\PY{p}{]}\PY{p}{)}
\PY{n}{trainset} \PY{o}{=} \PY{n}{torchvision}\PY{o}{.}\PY{n}{datasets}\PY{o}{.}\PY{n}{MNIST}\PY{p}{(}\PY{n}{root}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{../data}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{train}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{download}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{transform}\PY{o}{=}\PY{n}{transform}\PY{p}{)}
\PY{n}{trainloader} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{utils}\PY{o}{.}\PY{n}{data}\PY{o}{.}\PY{n}{DataLoader}\PY{p}{(}\PY{n}{trainset}\PY{p}{,} \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{64}\PY{p}{,} \PY{n}{shuffle}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{num\PYZus{}workers}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    Set the latent dimension

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{5}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{latent\PYZus{}dim} \PY{o}{=} \PY{l+m+mi}{256}
\end{Verbatim}
\end{tcolorbox}

    Create a models directory if it doesn't exist

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{6}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Create models directory if it doesn\PYZsq{}t exist}
\PY{n}{os}\PY{o}{.}\PY{n}{makedirs}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{models}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{exist\PYZus{}ok}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \subsection{Load the joint-training autoencoder
model}\label{load-the-joint-training-autoencoder-model}

    We load the model trained with a joint training objective.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{classifier} \PY{o}{=} \PY{n}{regene\PYZus{}models}\PY{o}{.}\PY{n}{Classifier}\PY{p}{(}\PY{n}{latent\PYZus{}dim}\PY{o}{=}\PY{n}{latent\PYZus{}dim}\PY{p}{,} \PY{n}{num\PYZus{}classes}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{,} \PY{n}{device}\PY{o}{=}\PY{n}{device}\PY{p}{)}
\PY{n}{decoder} \PY{o}{=} \PY{n}{regene\PYZus{}models}\PY{o}{.}\PY{n}{Decoder}\PY{p}{(}\PY{n}{latent\PYZus{}dim}\PY{o}{=}\PY{n}{latent\PYZus{}dim}\PY{p}{,} \PY{n}{device}\PY{o}{=}\PY{n}{device}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Load the trained models}
\PY{n}{classifier}\PY{o}{.}\PY{n}{load\PYZus{}state\PYZus{}dict}\PY{p}{(}\PY{n}{torch}\PY{o}{.}\PY{n}{load}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{models/joint\PYZus{}classifier.pth}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{map\PYZus{}location}\PY{o}{=}\PY{n}{device}\PY{p}{)}\PY{p}{)}
\PY{n}{decoder}\PY{o}{.}\PY{n}{load\PYZus{}state\PYZus{}dict}\PY{p}{(}\PY{n}{torch}\PY{o}{.}\PY{n}{load}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{models/joint\PYZus{}decoder.pth}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{map\PYZus{}location}\PY{o}{=}\PY{n}{device}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
/var/folders/tb/ccwl9r592hn9v\_xpq9s1bzlr0000gn/T/ipykernel\_43172/4034084385.py:5
: FutureWarning: You are using `torch.load` with `weights\_only=False` (the
current default value), which uses the default pickle module implicitly. It is
possible to construct malicious pickle data which will execute arbitrary code
during unpickling (See
https://github.com/pytorch/pytorch/blob/main/SECURITY.md\#untrusted-models for
more details). In a future release, the default value for `weights\_only` will be
flipped to `True`. This limits the functions that could be executed during
unpickling. Arbitrary objects will no longer be allowed to be loaded via this
mode unless they are explicitly allowlisted by the user via
`torch.serialization.add\_safe\_globals`. We recommend you start setting
`weights\_only=True` for any use case where you don't have full control of the
loaded file. Please open an issue on GitHub for any issues related to this
experimental feature.
  joint\_classifier.load\_state\_dict(torch.load('models/joint\_classifier.pth',
map\_location=device))
/var/folders/tb/ccwl9r592hn9v\_xpq9s1bzlr0000gn/T/ipykernel\_43172/4034084385.py:6
: FutureWarning: You are using `torch.load` with `weights\_only=False` (the
current default value), which uses the default pickle module implicitly. It is
possible to construct malicious pickle data which will execute arbitrary code
during unpickling (See
https://github.com/pytorch/pytorch/blob/main/SECURITY.md\#untrusted-models for
more details). In a future release, the default value for `weights\_only` will be
flipped to `True`. This limits the functions that could be executed during
unpickling. Arbitrary objects will no longer be allowed to be loaded via this
mode unless they are explicitly allowlisted by the user via
`torch.serialization.add\_safe\_globals`. We recommend you start setting
`weights\_only=True` for any use case where you don't have full control of the
loaded file. Please open an issue on GitHub for any issues related to this
experimental feature.
  joint\_decoder.load\_state\_dict(torch.load('models/joint\_decoder.pth',
map\_location=device))
    \end{Verbatim}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
<All keys matched successfully>
\end{Verbatim}
\end{tcolorbox}
        
    Get the most uncertain images, we need a non-shuffled loader for this.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Create a non\PYZhy{}shuffled loader for uncertainty calculation}
\PY{n}{eval\PYZus{}loader} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{utils}\PY{o}{.}\PY{n}{data}\PY{o}{.}\PY{n}{DataLoader}\PY{p}{(}\PY{n}{trainset}\PY{p}{,} \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{64}\PY{p}{,} \PY{n}{shuffle}\PY{o}{=}\PY{k+kc}{False}\PY{p}{,} \PY{n}{num\PYZus{}workers}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Get uncertainty scores for all training data points}
\PY{n}{uncertainties} \PY{o}{=} \PY{p}{[}\PY{p}{]}
\PY{n}{indices} \PY{o}{=} \PY{p}{[}\PY{p}{]}

\PY{n}{classifier}\PY{o}{.}\PY{n}{eval}\PY{p}{(}\PY{p}{)}
\PY{k}{with} \PY{n}{torch}\PY{o}{.}\PY{n}{no\PYZus{}grad}\PY{p}{(}\PY{p}{)}\PY{p}{:}
    \PY{k}{for} \PY{n}{i}\PY{p}{,} \PY{p}{(}\PY{n}{images}\PY{p}{,} \PY{n}{\PYZus{}}\PY{p}{)} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{eval\PYZus{}loader}\PY{p}{)}\PY{p}{:}
        \PY{n}{images} \PY{o}{=} \PY{n}{images}\PY{o}{.}\PY{n}{to}\PY{p}{(}\PY{n}{device}\PY{p}{)}
        \PY{c+c1}{\PYZsh{} Get latent representations and predictions}
        \PY{n}{z}\PY{p}{,} \PY{n}{logits} \PY{o}{=} \PY{n}{classifier}\PY{p}{(}\PY{n}{images}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Calculate uncertainty (entropy) for each prediction}
        \PY{n}{probs} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{functional}\PY{o}{.}\PY{n}{softmax}\PY{p}{(}\PY{n}{logits}\PY{p}{,} \PY{n}{dim}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
        \PY{n}{entropy} \PY{o}{=} \PY{o}{\PYZhy{}}\PY{p}{(}\PY{n}{probs} \PY{o}{*} \PY{n}{torch}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{probs} \PY{o}{+} \PY{l+m+mf}{1e\PYZhy{}10}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{n}{dim}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Store uncertainties and indices}
        \PY{n}{uncertainties}\PY{o}{.}\PY{n}{extend}\PY{p}{(}\PY{n}{entropy}\PY{o}{.}\PY{n}{cpu}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{numpy}\PY{p}{(}\PY{p}{)}\PY{p}{)}
        \PY{n}{indices}\PY{o}{.}\PY{n}{extend}\PY{p}{(}\PY{n+nb}{range}\PY{p}{(}\PY{n}{i}\PY{o}{*}\PY{n}{eval\PYZus{}loader}\PY{o}{.}\PY{n}{batch\PYZus{}size}\PY{p}{,} \PY{n+nb}{min}\PY{p}{(}\PY{p}{(}\PY{n}{i}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)}\PY{o}{*}\PY{n}{eval\PYZus{}loader}\PY{o}{.}\PY{n}{batch\PYZus{}size}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{trainset}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Convert to numpy arrays}
\PY{n}{uncertainties} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{uncertainties}\PY{p}{)}
\PY{n}{indices} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{indices}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Sort by uncertainty (descending order)}
\PY{n}{sorted\PYZus{}idx} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{argsort}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{n}{uncertainties}\PY{p}{)}
\PY{n}{sorted\PYZus{}uncertainties} \PY{o}{=} \PY{n}{uncertainties}\PY{p}{[}\PY{n}{sorted\PYZus{}idx}\PY{p}{]}
\PY{n}{sorted\PYZus{}data\PYZus{}indices} \PY{o}{=} \PY{n}{indices}\PY{p}{[}\PY{n}{sorted\PYZus{}idx}\PY{p}{]}

\PY{c+c1}{\PYZsh{} Verify the most uncertain predictions}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{Verifying top 5 most uncertain predictions:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{classifier}\PY{o}{.}\PY{n}{eval}\PY{p}{(}\PY{p}{)}
\PY{k}{with} \PY{n}{torch}\PY{o}{.}\PY{n}{no\PYZus{}grad}\PY{p}{(}\PY{p}{)}\PY{p}{:}
    \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{:}
        \PY{n}{idx} \PY{o}{=} \PY{n}{sorted\PYZus{}data\PYZus{}indices}\PY{p}{[}\PY{n}{i}\PY{p}{]}
        \PY{n}{image}\PY{p}{,} \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{trainset}\PY{p}{[}\PY{n}{idx}\PY{p}{]}
        \PY{n}{image} \PY{o}{=} \PY{n}{image}\PY{o}{.}\PY{n}{to}\PY{p}{(}\PY{n}{device}\PY{p}{)}\PY{o}{.}\PY{n}{unsqueeze}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{)}
        \PY{n}{\PYZus{}}\PY{p}{,} \PY{n}{logits} \PY{o}{=} \PY{n}{classifier}\PY{p}{(}\PY{n}{image}\PY{p}{)}
        \PY{n}{probs} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{functional}\PY{o}{.}\PY{n}{softmax}\PY{p}{(}\PY{n}{logits}\PY{p}{,} \PY{n}{dim}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
        \PY{n}{entropy} \PY{o}{=} \PY{o}{\PYZhy{}}\PY{p}{(}\PY{n}{probs} \PY{o}{*} \PY{n}{torch}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{probs} \PY{o}{+} \PY{l+m+mf}{1e\PYZhy{}10}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{n}{dim}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{Prediction }\PY{l+s+si}{\PYZob{}}\PY{n}{i}\PY{o}{+}\PY{l+m+mi}{1}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Stored entropy: }\PY{l+s+si}{\PYZob{}}\PY{n}{sorted\PYZus{}uncertainties}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{l+s+si}{:}\PY{l+s+s2}{.3f}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Recalculated entropy: }\PY{l+s+si}{\PYZob{}}\PY{n}{entropy}\PY{o}{.}\PY{n}{item}\PY{p}{(}\PY{p}{)}\PY{l+s+si}{:}\PY{l+s+s2}{.3f}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Probabilities: }\PY{l+s+si}{\PYZob{}}\PY{n}{probs}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{cpu}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{numpy}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{round}\PY{p}{(}\PY{l+m+mi}{3}\PY{p}{)}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{Most uncertain predictions have entropy: }\PY{l+s+si}{\PYZob{}}\PY{n}{sorted\PYZus{}uncertainties}\PY{p}{[}\PY{p}{:}\PY{l+m+mi}{5}\PY{p}{]}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Least uncertain predictions have entropy: }\PY{l+s+si}{\PYZob{}}\PY{n}{sorted\PYZus{}uncertainties}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{5}\PY{p}{:}\PY{p}{]}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]

Verifying top 5 most uncertain predictions:

Prediction 1:
Stored entropy: 1.371
Recalculated entropy: 1.371
Probabilities: [0.402 0.153 0.046 0.    0.    0.    0.086 0.    0.312 0.   ]

Prediction 2:
Stored entropy: 1.271
Recalculated entropy: 1.271
Probabilities: [0.    0.274 0.    0.    0.197 0.    0.    0.024 0.458 0.046]

Prediction 3:
Stored entropy: 1.135
Recalculated entropy: 1.135
Probabilities: [0.077 0.005 0.617 0.215 0.003 0.052 0.    0.    0.    0.032]

Prediction 4:
Stored entropy: 1.056
Recalculated entropy: 1.056
Probabilities: [0.186 0.    0.    0.001 0.    0.    0.498 0.    0.31  0.005]

Prediction 5:
Stored entropy: 1.055
Recalculated entropy: 1.055
Probabilities: [0.243 0.    0.    0.    0.    0.    0.475 0.    0.282 0.   ]

Most uncertain predictions have entropy: [1.3709209 1.270649  1.1351737 1.056384
1.0553004]
Least uncertain predictions have entropy: [2.6097019e-17 1.1480115e-17
6.4684300e-18 2.3343833e-18 2.2614270e-18]
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{50}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import}\PY{+w}{ }\PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot}\PY{+w}{ }\PY{k}{as}\PY{+w}{ }\PY{n+nn}{plt}
\PY{k+kn}{import}\PY{+w}{ }\PY{n+nn}{torch}

\PY{k}{def}\PY{+w}{ }\PY{n+nf}{plot\PYZus{}most\PYZus{}uncertain}\PY{p}{(}\PY{n}{trainset}\PY{p}{,} \PY{n}{sorted\PYZus{}data\PYZus{}indices}\PY{p}{,} \PY{n}{sorted\PYZus{}uncertainties}\PY{p}{,} \PY{n}{n\PYZus{}plot}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{:}
\PY{+w}{    }\PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
\PY{l+s+sd}{    Plots the top\PYZhy{}n most uncertain predictions from the training set.}

\PY{l+s+sd}{    Args:}
\PY{l+s+sd}{        trainset (torch.utils.data.Dataset): Dataset that returns (image, label) samples.}
\PY{l+s+sd}{        sorted\PYZus{}data\PYZus{}indices (np.ndarray): Array of indices sorted in descending order by uncertainty.}
\PY{l+s+sd}{        sorted\PYZus{}uncertainties (np.ndarray): Array of uncertainty (entropy) values, sorted to match sorted\PYZus{}data\PYZus{}indices.}
\PY{l+s+sd}{        n\PYZus{}plot (int): Number of images to plot.}
\PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
    \PY{c+c1}{\PYZsh{} Calculate number of rows needed}
    \PY{n}{images\PYZus{}per\PYZus{}row} \PY{o}{=} \PY{l+m+mi}{10}
    \PY{n}{n\PYZus{}rows} \PY{o}{=} \PY{p}{(}\PY{n}{n\PYZus{}plot} \PY{o}{\PYZhy{}} \PY{l+m+mi}{1}\PY{p}{)} \PY{o}{/}\PY{o}{/} \PY{n}{images\PYZus{}per\PYZus{}row} \PY{o}{+} \PY{l+m+mi}{1}
    
    \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{15}\PY{p}{,} \PY{l+m+mi}{3} \PY{o}{*} \PY{n}{n\PYZus{}rows}\PY{p}{)}\PY{p}{)}
    \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{n\PYZus{}plot}\PY{p}{)}\PY{p}{:}
        \PY{n}{data\PYZus{}idx} \PY{o}{=} \PY{n}{sorted\PYZus{}data\PYZus{}indices}\PY{p}{[}\PY{n}{i}\PY{p}{]}
        \PY{n}{image}\PY{p}{,} \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{trainset}\PY{p}{[}\PY{n}{data\PYZus{}idx}\PY{p}{]}
        
        \PY{c+c1}{\PYZsh{} If image is a torch.Tensor, convert it to a NumPy array.}
        \PY{k}{if} \PY{n}{torch}\PY{o}{.}\PY{n}{is\PYZus{}tensor}\PY{p}{(}\PY{n}{image}\PY{p}{)}\PY{p}{:}
            \PY{n}{image} \PY{o}{=} \PY{n}{image}\PY{o}{.}\PY{n}{cpu}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{detach}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{numpy}\PY{p}{(}\PY{p}{)}
            \PY{c+c1}{\PYZsh{} If the image has one channel [1, H, W], squeeze out the channel dimension.}
            \PY{k}{if} \PY{n}{image}\PY{o}{.}\PY{n}{ndim} \PY{o}{==} \PY{l+m+mi}{3} \PY{o+ow}{and} \PY{n}{image}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{==} \PY{l+m+mi}{1}\PY{p}{:}
                \PY{n}{image} \PY{o}{=} \PY{n}{image}\PY{o}{.}\PY{n}{squeeze}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{)}
        
        \PY{n}{row} \PY{o}{=} \PY{n}{i} \PY{o}{/}\PY{o}{/} \PY{n}{images\PYZus{}per\PYZus{}row}
        \PY{n}{col} \PY{o}{=} \PY{n}{i} \PY{o}{\PYZpc{}} \PY{n}{images\PYZus{}per\PYZus{}row}
        \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{n}{n\PYZus{}rows}\PY{p}{,} \PY{n}{images\PYZus{}per\PYZus{}row}\PY{p}{,} \PY{n}{i} \PY{o}{+} \PY{l+m+mi}{1}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{image}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gray}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Entropy: }\PY{l+s+si}{\PYZob{}}\PY{n}{sorted\PYZus{}uncertainties}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{l+s+si}{:}\PY{l+s+s2}{.2f}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{axis}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{off}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
    
    \PY{n}{plt}\PY{o}{.}\PY{n}{suptitle}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Most Uncertain Predictions}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
    \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{51}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Plot the most uncertain predictions}
\PY{n}{plot\PYZus{}most\PYZus{}uncertain}\PY{p}{(}\PY{n}{trainset}\PY{p}{,} \PY{n}{sorted\PYZus{}data\PYZus{}indices}\PY{p}{,} \PY{n}{sorted\PYZus{}uncertainties}\PY{p}{,} \PY{n}{n\PYZus{}plot}\PY{o}{=}\PY{l+m+mi}{20}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{test-new-clue_files/test-new-clue_18_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsection{Test new CLUE
implementation}\label{test-new-clue-implementation}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{55}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Get the most uncertain image and its latent representation}
\PY{n}{most\PYZus{}uncertain\PYZus{}idx} \PY{o}{=} \PY{n}{sorted\PYZus{}data\PYZus{}indices}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}
\PY{n}{uncertain\PYZus{}image}\PY{p}{,} \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{trainset}\PY{p}{[}\PY{n}{most\PYZus{}uncertain\PYZus{}idx}\PY{p}{]}
\PY{n}{uncertain\PYZus{}image} \PY{o}{=} \PY{n}{uncertain\PYZus{}image}\PY{o}{.}\PY{n}{to}\PY{p}{(}\PY{n}{device}\PY{p}{)}\PY{o}{.}\PY{n}{unsqueeze}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Add batch dimension}

\PY{c+c1}{\PYZsh{} Get its latent representation}
\PY{n}{classifier}\PY{o}{.}\PY{n}{eval}\PY{p}{(}\PY{p}{)}
\PY{k}{with} \PY{n}{torch}\PY{o}{.}\PY{n}{no\PYZus{}grad}\PY{p}{(}\PY{p}{)}\PY{p}{:}
    \PY{n}{z0}\PY{p}{,} \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{classifier}\PY{p}{(}\PY{n}{uncertain\PYZus{}image}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Initialize CLUE}
\PY{n}{clue} \PY{o}{=} \PY{n}{new\PYZus{}CLUE}\PY{o}{.}\PY{n}{SimpleCLUE}\PY{p}{(}
    \PY{n}{classifier}\PY{o}{=}\PY{n}{classifier}\PY{p}{,}
    \PY{n}{z0}\PY{o}{=}\PY{n}{z0}\PY{p}{,}
    \PY{n}{uncertainty\PYZus{}weight}\PY{o}{=}\PY{l+m+mf}{1.0}\PY{p}{,}
    \PY{n}{distance\PYZus{}weight}\PY{o}{=}\PY{l+m+mf}{0.01}\PY{p}{,}
    \PY{n}{lr}\PY{o}{=}\PY{l+m+mf}{0.1}\PY{p}{,}
    \PY{n}{device}\PY{o}{=}\PY{n}{device}
\PY{p}{)}

\PY{c+c1}{\PYZsh{} Optimize to find explanation}
\PY{n}{z\PYZus{}explained} \PY{o}{=} \PY{n}{clue}\PY{o}{.}\PY{n}{optimize}\PY{p}{(}\PY{n}{steps}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Generate reconstructions using decoder}
\PY{k}{with} \PY{n}{torch}\PY{o}{.}\PY{n}{no\PYZus{}grad}\PY{p}{(}\PY{p}{)}\PY{p}{:}
    \PY{c+c1}{\PYZsh{} Original reconstruction}
    \PY{n}{original\PYZus{}recon} \PY{o}{=} \PY{n}{decoder}\PY{p}{(}\PY{n}{z0}\PY{p}{)}
    \PY{c+c1}{\PYZsh{} CLUE reconstruction  }
    \PY{n}{clue\PYZus{}recon} \PY{o}{=} \PY{n}{decoder}\PY{p}{(}\PY{n}{z\PYZus{}explained}\PY{p}{)}
    
    \PY{c+c1}{\PYZsh{} Get predictions and uncertainties}
    \PY{c+c1}{\PYZsh{} Use only the classifier head for the latent vectors}
    \PY{n}{original\PYZus{}logits} \PY{o}{=} \PY{n}{classifier}\PY{o}{.}\PY{n}{classifier}\PY{p}{(}\PY{n}{z0}\PY{p}{)}
    \PY{n}{explained\PYZus{}logits} \PY{o}{=} \PY{n}{classifier}\PY{o}{.}\PY{n}{classifier}\PY{p}{(}\PY{n}{z\PYZus{}explained}\PY{p}{)}
    
    \PY{n}{original\PYZus{}probs} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{functional}\PY{o}{.}\PY{n}{softmax}\PY{p}{(}\PY{n}{original\PYZus{}logits}\PY{p}{,} \PY{n}{dim}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
    \PY{n}{explained\PYZus{}probs} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{functional}\PY{o}{.}\PY{n}{softmax}\PY{p}{(}\PY{n}{explained\PYZus{}logits}\PY{p}{,} \PY{n}{dim}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
    
    \PY{n}{original\PYZus{}entropy} \PY{o}{=} \PY{o}{\PYZhy{}}\PY{p}{(}\PY{n}{original\PYZus{}probs} \PY{o}{*} \PY{n}{torch}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{original\PYZus{}probs} \PY{o}{+} \PY{l+m+mf}{1e\PYZhy{}10}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}
    \PY{n}{explained\PYZus{}entropy} \PY{o}{=} \PY{o}{\PYZhy{}}\PY{p}{(}\PY{n}{explained\PYZus{}probs} \PY{o}{*} \PY{n}{torch}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{explained\PYZus{}probs} \PY{o}{+} \PY{l+m+mf}{1e\PYZhy{}10}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Plot results}
\PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{15}\PY{p}{,} \PY{l+m+mi}{5}\PY{p}{)}\PY{p}{)}

\PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{131}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{uncertain\PYZus{}image}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{cpu}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gray}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Original Image}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{Entropy: }\PY{l+s+si}{\PYZob{}}\PY{n}{original\PYZus{}entropy}\PY{l+s+si}{:}\PY{l+s+s1}{.3f}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{axis}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{off}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

\PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{132}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{original\PYZus{}recon}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{cpu}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{detach}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gray}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Original Reconstruction}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{axis}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{off}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

\PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{133}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{clue\PYZus{}recon}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{cpu}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{detach}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gray}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{CLUE Reconstruction}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{Entropy: }\PY{l+s+si}{\PYZob{}}\PY{n}{explained\PYZus{}entropy}\PY{l+s+si}{:}\PY{l+s+s1}{.3f}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{axis}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{off}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

\PY{n}{plt}\PY{o}{.}\PY{n}{tight\PYZus{}layout}\PY{p}{(}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Print probabilities}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{Class probabilities:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Original:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{original\PYZus{}probs}\PY{o}{.}\PY{n}{cpu}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{numpy}\PY{p}{(}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{round}\PY{p}{(}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Explained:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{explained\PYZus{}probs}\PY{o}{.}\PY{n}{cpu}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{numpy}\PY{p}{(}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{round}\PY{p}{(}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Step 00: Loss: 1.2706, Entropy: 1.2706, Distance: 0.0000
Step 01: Loss: 0.6485, Entropy: 0.6325, Distance: 1.6000
Step 02: Loss: 0.2080, Entropy: 0.1782, Distance: 2.9774
Step 03: Loss: 0.0866, Entropy: 0.0437, Distance: 4.2846
Step 04: Loss: 0.0663, Entropy: 0.0122, Distance: 5.4093
Step 05: Loss: 0.0677, Entropy: 0.0041, Distance: 6.3582
Step 06: Loss: 0.0732, Entropy: 0.0016, Distance: 7.1597
Step 07: Loss: 0.0791, Entropy: 0.0007, Distance: 7.8395
Step 08: Loss: 0.0845, Entropy: 0.0003, Distance: 8.4177
Step 09: Loss: 0.0893, Entropy: 0.0002, Distance: 8.9101
Step 10: Loss: 0.0934, Entropy: 0.0001, Distance: 9.3289
Step 11: Loss: 0.0969, Entropy: 0.0001, Distance: 9.6839
Step 12: Loss: 0.0999, Entropy: 0.0000, Distance: 9.9832
Step 13: Loss: 0.1024, Entropy: 0.0000, Distance: 10.2334
Step 14: Loss: 0.1044, Entropy: 0.0000, Distance: 10.4402
Step 15: Loss: 0.1061, Entropy: 0.0000, Distance: 10.6084
Step 16: Loss: 0.1074, Entropy: 0.0000, Distance: 10.7422
Step 17: Loss: 0.1085, Entropy: 0.0000, Distance: 10.8450
Step 18: Loss: 0.1092, Entropy: 0.0000, Distance: 10.9201
Step 19: Loss: 0.1097, Entropy: 0.0000, Distance: 10.9704
Step 20: Loss: 0.1100, Entropy: 0.0000, Distance: 10.9982
Step 21: Loss: 0.1101, Entropy: 0.0000, Distance: 11.0058
Step 22: Loss: 0.1100, Entropy: 0.0000, Distance: 10.9953
Step 23: Loss: 0.1097, Entropy: 0.0000, Distance: 10.9684
Step 24: Loss: 0.1093, Entropy: 0.0000, Distance: 10.9268
Step 25: Loss: 0.1087, Entropy: 0.0000, Distance: 10.8719
Step 26: Loss: 0.1081, Entropy: 0.0000, Distance: 10.8051
Step 27: Loss: 0.1073, Entropy: 0.0000, Distance: 10.7277
Step 28: Loss: 0.1064, Entropy: 0.0000, Distance: 10.6406
Step 29: Loss: 0.1055, Entropy: 0.0000, Distance: 10.5451
Step 30: Loss: 0.1044, Entropy: 0.0000, Distance: 10.4419
Step 31: Loss: 0.1033, Entropy: 0.0000, Distance: 10.3319
Step 32: Loss: 0.1022, Entropy: 0.0000, Distance: 10.2158
Step 33: Loss: 0.1010, Entropy: 0.0000, Distance: 10.0945
Step 34: Loss: 0.0997, Entropy: 0.0000, Distance: 9.9684
Step 35: Loss: 0.0984, Entropy: 0.0000, Distance: 9.8382
Step 36: Loss: 0.0971, Entropy: 0.0000, Distance: 9.7043
Step 37: Loss: 0.0957, Entropy: 0.0000, Distance: 9.5673
Step 38: Loss: 0.0943, Entropy: 0.0000, Distance: 9.4276
Step 39: Loss: 0.0929, Entropy: 0.0000, Distance: 9.2857
Step 40: Loss: 0.0915, Entropy: 0.0000, Distance: 9.1417
Step 41: Loss: 0.0900, Entropy: 0.0000, Distance: 8.9962
Step 42: Loss: 0.0885, Entropy: 0.0000, Distance: 8.8495
Step 43: Loss: 0.0871, Entropy: 0.0001, Distance: 8.7017
Step 44: Loss: 0.0856, Entropy: 0.0001, Distance: 8.5532
Step 45: Loss: 0.0841, Entropy: 0.0001, Distance: 8.4042
Step 46: Loss: 0.0826, Entropy: 0.0001, Distance: 8.2550
Step 47: Loss: 0.0812, Entropy: 0.0001, Distance: 8.1057
Step 48: Loss: 0.0797, Entropy: 0.0001, Distance: 7.9565
Step 49: Loss: 0.0782, Entropy: 0.0001, Distance: 7.8075
Step 50: Loss: 0.0768, Entropy: 0.0002, Distance: 7.6590
Step 51: Loss: 0.0753, Entropy: 0.0002, Distance: 7.5111
Step 52: Loss: 0.0739, Entropy: 0.0002, Distance: 7.3638
Step 53: Loss: 0.0725, Entropy: 0.0003, Distance: 7.2174
Step 54: Loss: 0.0711, Entropy: 0.0004, Distance: 7.0720
Step 55: Loss: 0.0697, Entropy: 0.0004, Distance: 6.9276
Step 56: Loss: 0.0684, Entropy: 0.0005, Distance: 6.7845
Step 57: Loss: 0.0670, Entropy: 0.0006, Distance: 6.6427
Step 58: Loss: 0.0658, Entropy: 0.0007, Distance: 6.5025
Step 59: Loss: 0.0645, Entropy: 0.0009, Distance: 6.3640
Step 60: Loss: 0.0633, Entropy: 0.0011, Distance: 6.2274
Step 61: Loss: 0.0622, Entropy: 0.0013, Distance: 6.0930
Step 62: Loss: 0.0611, Entropy: 0.0015, Distance: 5.9609
Step 63: Loss: 0.0601, Entropy: 0.0018, Distance: 5.8315
Step 64: Loss: 0.0592, Entropy: 0.0021, Distance: 5.7050
Step 65: Loss: 0.0583, Entropy: 0.0025, Distance: 5.5819
Step 66: Loss: 0.0576, Entropy: 0.0029, Distance: 5.4625
Step 67: Loss: 0.0569, Entropy: 0.0034, Distance: 5.3473
Step 68: Loss: 0.0564, Entropy: 0.0040, Distance: 5.2368
Step 69: Loss: 0.0559, Entropy: 0.0046, Distance: 5.1316
Step 70: Loss: 0.0556, Entropy: 0.0052, Distance: 5.0322
Step 71: Loss: 0.0553, Entropy: 0.0059, Distance: 4.9393
Step 72: Loss: 0.0552, Entropy: 0.0066, Distance: 4.8535
Step 73: Loss: 0.0551, Entropy: 0.0073, Distance: 4.7754
Step 74: Loss: 0.0551, Entropy: 0.0080, Distance: 4.7057
Step 75: Loss: 0.0551, Entropy: 0.0086, Distance: 4.6449
Step 76: Loss: 0.0551, Entropy: 0.0091, Distance: 4.5933
Step 77: Loss: 0.0551, Entropy: 0.0096, Distance: 4.5513
Step 78: Loss: 0.0551, Entropy: 0.0099, Distance: 4.5190
Step 79: Loss: 0.0550, Entropy: 0.0101, Distance: 4.4962
Step 80: Loss: 0.0550, Entropy: 0.0101, Distance: 4.4826
Step 81: Loss: 0.0549, Entropy: 0.0101, Distance: 4.4776
Step 82: Loss: 0.0548, Entropy: 0.0100, Distance: 4.4803
Step 83: Loss: 0.0546, Entropy: 0.0097, Distance: 4.4898
Step 84: Loss: 0.0545, Entropy: 0.0095, Distance: 4.5049
Step 85: Loss: 0.0544, Entropy: 0.0092, Distance: 4.5244
Step 86: Loss: 0.0543, Entropy: 0.0088, Distance: 4.5471
Step 87: Loss: 0.0542, Entropy: 0.0085, Distance: 4.5718
Step 88: Loss: 0.0542, Entropy: 0.0082, Distance: 4.5974
Step 89: Loss: 0.0541, Entropy: 0.0079, Distance: 4.6228
Step 90: Loss: 0.0541, Entropy: 0.0076, Distance: 4.6473
Step 91: Loss: 0.0541, Entropy: 0.0074, Distance: 4.6701
Step 92: Loss: 0.0540, Entropy: 0.0071, Distance: 4.6906
Step 93: Loss: 0.0540, Entropy: 0.0069, Distance: 4.7084
Step 94: Loss: 0.0540, Entropy: 0.0068, Distance: 4.7233
Step 95: Loss: 0.0540, Entropy: 0.0067, Distance: 4.7351
Step 96: Loss: 0.0540, Entropy: 0.0066, Distance: 4.7437
Step 97: Loss: 0.0540, Entropy: 0.0065, Distance: 4.7494
Step 98: Loss: 0.0540, Entropy: 0.0065, Distance: 4.7521
Step 99: Loss: 0.0540, Entropy: 0.0065, Distance: 4.7522
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{test-new-clue_files/test-new-clue_20_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]

Class probabilities:
Original: [0.    0.274 0.    0.    0.197 0.    0.    0.024 0.458 0.046]
Explained: [0.    0.    0.    0.    0.    0.    0.    0.    0.999 0.   ]
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Get latent codes for 500 training images to create TSNE visualization}
\PY{n}{latent\PYZus{}codes} \PY{o}{=} \PY{p}{[}\PY{p}{]}
\PY{n}{labels\PYZus{}list} \PY{o}{=} \PY{p}{[}\PY{p}{]}
\PY{k}{with} \PY{n}{torch}\PY{o}{.}\PY{n}{no\PYZus{}grad}\PY{p}{(}\PY{p}{)}\PY{p}{:}
    \PY{k}{for} \PY{n}{i}\PY{p}{,} \PY{p}{(}\PY{n}{images}\PY{p}{,} \PY{n}{labels}\PY{p}{)} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{trainloader}\PY{p}{)}\PY{p}{:}
        \PY{k}{if} \PY{n}{i} \PY{o}{\PYZgt{}}\PY{o}{=} \PY{l+m+mi}{500}\PY{o}{/}\PY{n}{images}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{:}  \PY{c+c1}{\PYZsh{} Stop after \PYZti{}500 images}
            \PY{k}{break}
        \PY{n}{images} \PY{o}{=} \PY{n}{images}\PY{o}{.}\PY{n}{to}\PY{p}{(}\PY{n}{device}\PY{p}{)}
        \PY{n}{z}\PY{p}{,} \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{classifier}\PY{p}{(}\PY{n}{images}\PY{p}{)}
        \PY{n}{latent\PYZus{}codes}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{z}\PY{o}{.}\PY{n}{cpu}\PY{p}{(}\PY{p}{)}\PY{p}{)}
        \PY{n}{labels\PYZus{}list}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{labels}\PY{p}{)}
\PY{n}{latent\PYZus{}codes} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{cat}\PY{p}{(}\PY{n}{latent\PYZus{}codes}\PY{p}{,} \PY{n}{dim}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
\PY{n}{labels} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{cat}\PY{p}{(}\PY{n}{labels\PYZus{}list}\PY{p}{,} \PY{n}{dim}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Add z0 and z\PYZus{}explained to the latent codes}
\PY{n}{all\PYZus{}latents} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{cat}\PY{p}{(}\PY{p}{[}\PY{n}{latent\PYZus{}codes}\PY{p}{,} \PY{n}{z0}\PY{o}{.}\PY{n}{cpu}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{z\PYZus{}explained}\PY{o}{.}\PY{n}{cpu}\PY{p}{(}\PY{p}{)}\PY{p}{]}\PY{p}{,} \PY{n}{dim}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Perform t\PYZhy{}SNE}
\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{manifold}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{TSNE}
\PY{n}{tsne} \PY{o}{=} \PY{n}{TSNE}\PY{p}{(}\PY{n}{n\PYZus{}components}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{42}\PY{p}{)}
\PY{n}{latents\PYZus{}2d} \PY{o}{=} \PY{n}{tsne}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{all\PYZus{}latents}\PY{o}{.}\PY{n}{numpy}\PY{p}{(}\PY{p}{)}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Plot t\PYZhy{}SNE}
\PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{,} \PY{l+m+mi}{8}\PY{p}{)}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Create scatter plot for each class}
\PY{c+c1}{\PYZsh{} Only plot the training points (excluding the last 2 points which are z0 and z\PYZus{}explained)}
\PY{n}{training\PYZus{}latents\PYZus{}2d} \PY{o}{=} \PY{n}{latents\PYZus{}2d}\PY{p}{[}\PY{p}{:}\PY{o}{\PYZhy{}}\PY{l+m+mi}{2}\PY{p}{]}
\PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{)}\PY{p}{:}
    \PY{n}{mask} \PY{o}{=} \PY{n}{labels} \PY{o}{==} \PY{n}{i}
    \PY{n}{plt}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{training\PYZus{}latents\PYZus{}2d}\PY{p}{[}\PY{n}{mask}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{training\PYZus{}latents\PYZus{}2d}\PY{p}{[}\PY{n}{mask}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} 
               \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.5}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+sa}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Class }\PY{l+s+si}{\PYZob{}}\PY{n}{i}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{s}\PY{o}{=}\PY{l+m+mi}{20}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Reduced point size to 20}

\PY{c+c1}{\PYZsh{} Plot original and explained points}
\PY{n}{plt}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{latents\PYZus{}2d}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{latents\PYZus{}2d}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{c}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{black}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{s}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Original (z0)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{latents\PYZus{}2d}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{latents\PYZus{}2d}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{c}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{red}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{s}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Explained (z)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{p}{[}\PY{n}{latents\PYZus{}2d}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{latents\PYZus{}2d}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{]}\PY{p}{]}\PY{p}{,} 
         \PY{p}{[}\PY{n}{latents\PYZus{}2d}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{latents\PYZus{}2d}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{]}\PY{p}{,} 
         \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{k\PYZhy{}\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.5}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Calculate and print distance between original and explained points in t\PYZhy{}SNE space}
\PY{n}{tsne\PYZus{}distance} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{sqrt}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{(}\PY{n}{latents\PYZus{}2d}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{2}\PY{p}{]} \PY{o}{\PYZhy{}} \PY{n}{latents\PYZus{}2d}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{o}{*}\PY{o}{*}\PY{l+m+mi}{2}\PY{p}{)}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{Distance between original and explained points in t\PYZhy{}SNE space: }\PY{l+s+si}{\PYZob{}}\PY{n}{tsne\PYZus{}distance}\PY{l+s+si}{:}\PY{l+s+s2}{.3f}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{t\PYZhy{}SNE visualization of latent space}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]

Distance between original and explained points in t-SNE space: 0.054
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{test-new-clue_files/test-new-clue_21_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsection{Load the SVAE}\label{load-the-svae}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{7}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{importlib}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{reload}
\PY{k+kn}{import}\PY{+w}{ }\PY{n+nn}{MyImplementation}\PY{n+nn}{.}\PY{n+nn}{models}\PY{n+nn}{.}\PY{n+nn}{SVAE}\PY{+w}{ }\PY{k}{as}\PY{+w}{ }\PY{n+nn}{SVAE}
\PY{n}{reload}\PY{p}{(}\PY{n}{SVAE}\PY{p}{)}
\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{MyImplementation}\PY{n+nn}{.}\PY{n+nn}{models}\PY{n+nn}{.}\PY{n+nn}{SVAE}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{SVAE}

\PY{n}{svae} \PY{o}{=} \PY{n}{SVAE}\PY{p}{(}\PY{n}{latent\PYZus{}dim}\PY{o}{=}\PY{n}{latent\PYZus{}dim}\PY{p}{,} \PY{n}{num\PYZus{}classes}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{,} \PY{n}{device}\PY{o}{=}\PY{n}{device}\PY{p}{)}
\PY{n}{svae}\PY{o}{.}\PY{n}{load\PYZus{}state\PYZus{}dict}\PY{p}{(}\PY{n}{torch}\PY{o}{.}\PY{n}{load}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{models/svae.pth}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{map\PYZus{}location}\PY{o}{=}\PY{n}{device}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
/var/folders/tb/ccwl9r592hn9v\_xpq9s1bzlr0000gn/T/ipykernel\_51814/2112457366.py:7
: FutureWarning: You are using `torch.load` with `weights\_only=False` (the
current default value), which uses the default pickle module implicitly. It is
possible to construct malicious pickle data which will execute arbitrary code
during unpickling (See
https://github.com/pytorch/pytorch/blob/main/SECURITY.md\#untrusted-models for
more details). In a future release, the default value for `weights\_only` will be
flipped to `True`. This limits the functions that could be executed during
unpickling. Arbitrary objects will no longer be allowed to be loaded via this
mode unless they are explicitly allowlisted by the user via
`torch.serialization.add\_safe\_globals`. We recommend you start setting
`weights\_only=True` for any use case where you don't have full control of the
loaded file. Please open an issue on GitHub for any issues related to this
experimental feature.
  svae.load\_state\_dict(torch.load('models/svae.pth', map\_location=device))
    \end{Verbatim}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{7}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
<All keys matched successfully>
\end{Verbatim}
\end{tcolorbox}
        
    Test the model on some images

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{8}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Get a batch of images from the trainloader}
\PY{n}{svae}\PY{o}{.}\PY{n}{eval}\PY{p}{(}\PY{p}{)}
\PY{k}{with} \PY{n}{torch}\PY{o}{.}\PY{n}{no\PYZus{}grad}\PY{p}{(}\PY{p}{)}\PY{p}{:}
    \PY{c+c1}{\PYZsh{} Get one batch of images}
    \PY{n}{images}\PY{p}{,} \PY{n}{labels} \PY{o}{=} \PY{n+nb}{next}\PY{p}{(}\PY{n+nb}{iter}\PY{p}{(}\PY{n}{trainloader}\PY{p}{)}\PY{p}{)}
    \PY{n}{images} \PY{o}{=} \PY{n}{images}\PY{o}{.}\PY{n}{to}\PY{p}{(}\PY{n}{device}\PY{p}{)}
    \PY{n}{labels} \PY{o}{=} \PY{n}{labels}\PY{o}{.}\PY{n}{to}\PY{p}{(}\PY{n}{device}\PY{p}{)}
    
    \PY{c+c1}{\PYZsh{} Pass through SVAE}
    \PY{n}{recon\PYZus{}images}\PY{p}{,} \PY{n}{pred\PYZus{}labels}\PY{p}{,} \PY{n}{mu}\PY{p}{,} \PY{n}{log\PYZus{}var} \PY{o}{=} \PY{n}{svae}\PY{p}{(}\PY{n}{images}\PY{p}{)}
    
    \PY{c+c1}{\PYZsh{} Get predictions}
    \PY{n}{pred\PYZus{}classes} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{argmax}\PY{p}{(}\PY{n}{pred\PYZus{}labels}\PY{p}{,} \PY{n}{dim}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Plot the results}
\PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{20}\PY{p}{,} \PY{l+m+mi}{4}\PY{p}{)}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Plot original images}
\PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{)}\PY{p}{:}
    \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{,} \PY{n}{i}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)}
    \PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{images}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{o}{.}\PY{n}{cpu}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{squeeze}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gray}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Orig: }\PY{l+s+si}{\PYZob{}}\PY{n}{labels}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{o}{.}\PY{n}{item}\PY{p}{(}\PY{p}{)}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{n}{plt}\PY{o}{.}\PY{n}{axis}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{off}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Plot reconstructed images}
\PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{)}\PY{p}{:}
    \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{,} \PY{n}{i}\PY{o}{+}\PY{l+m+mi}{11}\PY{p}{)}
    \PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{recon\PYZus{}images}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{o}{.}\PY{n}{cpu}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{squeeze}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gray}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Pred: }\PY{l+s+si}{\PYZob{}}\PY{n}{pred\PYZus{}classes}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{o}{.}\PY{n}{item}\PY{p}{(}\PY{p}{)}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{n}{plt}\PY{o}{.}\PY{n}{axis}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{off}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

\PY{n}{plt}\PY{o}{.}\PY{n}{tight\PYZus{}layout}\PY{p}{(}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{test-new-clue_files/test-new-clue_25_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Get the most uncertain images, we need a non-shuffled loader for this.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{9}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Create a non\PYZhy{}shuffled loader for uncertainty calculation}
\PY{n}{eval\PYZus{}loader} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{utils}\PY{o}{.}\PY{n}{data}\PY{o}{.}\PY{n}{DataLoader}\PY{p}{(}\PY{n}{trainset}\PY{p}{,} \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{64}\PY{p}{,} \PY{n}{shuffle}\PY{o}{=}\PY{k+kc}{False}\PY{p}{,} \PY{n}{num\PYZus{}workers}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Get uncertainty scores for all training data points}
\PY{n}{uncertainties} \PY{o}{=} \PY{p}{[}\PY{p}{]}
\PY{n}{indices} \PY{o}{=} \PY{p}{[}\PY{p}{]}

\PY{n}{svae}\PY{o}{.}\PY{n}{eval}\PY{p}{(}\PY{p}{)}
\PY{k}{with} \PY{n}{torch}\PY{o}{.}\PY{n}{no\PYZus{}grad}\PY{p}{(}\PY{p}{)}\PY{p}{:}
    \PY{k}{for} \PY{n}{i}\PY{p}{,} \PY{p}{(}\PY{n}{images}\PY{p}{,} \PY{n}{\PYZus{}}\PY{p}{)} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{eval\PYZus{}loader}\PY{p}{)}\PY{p}{:}
        \PY{n}{images} \PY{o}{=} \PY{n}{images}\PY{o}{.}\PY{n}{to}\PY{p}{(}\PY{n}{device}\PY{p}{)}
        \PY{c+c1}{\PYZsh{} Get predictions from SVAE}
        \PY{n}{\PYZus{}}\PY{p}{,} \PY{n}{logits}\PY{p}{,} \PY{n}{\PYZus{}}\PY{p}{,} \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{svae}\PY{p}{(}\PY{n}{images}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Calculate uncertainty (entropy) for each prediction}
        \PY{n}{probs} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{functional}\PY{o}{.}\PY{n}{softmax}\PY{p}{(}\PY{n}{logits}\PY{p}{,} \PY{n}{dim}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
        \PY{n}{entropy} \PY{o}{=} \PY{o}{\PYZhy{}}\PY{p}{(}\PY{n}{probs} \PY{o}{*} \PY{n}{torch}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{probs} \PY{o}{+} \PY{l+m+mf}{1e\PYZhy{}10}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{n}{dim}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Store uncertainties and indices}
        \PY{n}{uncertainties}\PY{o}{.}\PY{n}{extend}\PY{p}{(}\PY{n}{entropy}\PY{o}{.}\PY{n}{cpu}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{numpy}\PY{p}{(}\PY{p}{)}\PY{p}{)}
        \PY{n}{indices}\PY{o}{.}\PY{n}{extend}\PY{p}{(}\PY{n+nb}{range}\PY{p}{(}\PY{n}{i}\PY{o}{*}\PY{n}{eval\PYZus{}loader}\PY{o}{.}\PY{n}{batch\PYZus{}size}\PY{p}{,} \PY{n+nb}{min}\PY{p}{(}\PY{p}{(}\PY{n}{i}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)}\PY{o}{*}\PY{n}{eval\PYZus{}loader}\PY{o}{.}\PY{n}{batch\PYZus{}size}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{trainset}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Convert to numpy arrays}
\PY{n}{uncertainties} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{uncertainties}\PY{p}{)}
\PY{n}{indices} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{indices}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Sort by uncertainty (descending order)}
\PY{n}{sorted\PYZus{}idx} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{argsort}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{n}{uncertainties}\PY{p}{)}
\PY{n}{sorted\PYZus{}uncertainties\PYZus{}svae} \PY{o}{=} \PY{n}{uncertainties}\PY{p}{[}\PY{n}{sorted\PYZus{}idx}\PY{p}{]}
\PY{n}{sorted\PYZus{}data\PYZus{}indices\PYZus{}svae} \PY{o}{=} \PY{n}{indices}\PY{p}{[}\PY{n}{sorted\PYZus{}idx}\PY{p}{]}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{Most uncertain predictions have entropy: }\PY{l+s+si}{\PYZob{}}\PY{n}{sorted\PYZus{}uncertainties\PYZus{}svae}\PY{p}{[}\PY{p}{:}\PY{l+m+mi}{5}\PY{p}{]}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Least uncertain predictions have entropy: }\PY{l+s+si}{\PYZob{}}\PY{n}{sorted\PYZus{}uncertainties\PYZus{}svae}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{5}\PY{p}{:}\PY{p}{]}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]

Most uncertain predictions have entropy: [1.7587771 1.7497175 1.6841661
1.5472646 1.508778 ]
Least uncertain predictions have entropy: [1.9333633e-08 1.0200183e-08
7.9712823e-09 7.7774480e-09 2.9103666e-09]
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{78}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Plot the most uncertain predictions}
\PY{n}{plot\PYZus{}most\PYZus{}uncertain}\PY{p}{(}\PY{n}{trainset}\PY{p}{,} \PY{n}{sorted\PYZus{}data\PYZus{}indices\PYZus{}svae}\PY{p}{,} \PY{n}{sorted\PYZus{}uncertainties\PYZus{}svae}\PY{p}{,} \PY{n}{n\PYZus{}plot}\PY{o}{=}\PY{l+m+mi}{20}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{test-new-clue_files/test-new-clue_28_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsubsection{Apply CLUE to SVAE}\label{apply-clue-to-svae}

    A single example of a counterfactual explanation

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{10}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Get the most uncertain image and its latent representation}
\PY{n}{most\PYZus{}uncertain\PYZus{}idx} \PY{o}{=} \PY{n}{sorted\PYZus{}data\PYZus{}indices\PYZus{}svae}\PY{p}{[}\PY{l+m+mi}{13}\PY{p}{]}
\PY{n}{uncertain\PYZus{}image}\PY{p}{,} \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{trainset}\PY{p}{[}\PY{n}{most\PYZus{}uncertain\PYZus{}idx}\PY{p}{]}
\PY{n}{uncertain\PYZus{}image} \PY{o}{=} \PY{n}{uncertain\PYZus{}image}\PY{o}{.}\PY{n}{to}\PY{p}{(}\PY{n}{device}\PY{p}{)}\PY{o}{.}\PY{n}{unsqueeze}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Add batch dimension}

\PY{c+c1}{\PYZsh{} Get its latent representation}
\PY{n}{svae}\PY{o}{.}\PY{n}{eval}\PY{p}{(}\PY{p}{)}
\PY{k}{with} \PY{n}{torch}\PY{o}{.}\PY{n}{no\PYZus{}grad}\PY{p}{(}\PY{p}{)}\PY{p}{:}
    \PY{n}{\PYZus{}}\PY{p}{,} \PY{n}{\PYZus{}}\PY{p}{,} \PY{n}{mu}\PY{p}{,} \PY{n}{log\PYZus{}var} \PY{o}{=} \PY{n}{svae}\PY{p}{(}\PY{n}{uncertain\PYZus{}image}\PY{p}{)}
    \PY{n}{z0} \PY{o}{=} \PY{n}{svae}\PY{o}{.}\PY{n}{reparameterize}\PY{p}{(}\PY{n}{mu}\PY{p}{,} \PY{n}{log\PYZus{}var}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Initialize CLUE}
\PY{n}{clue} \PY{o}{=} \PY{n}{new\PYZus{}CLUE}\PY{o}{.}\PY{n}{SimpleCLUE}\PY{p}{(}
    \PY{n}{model}\PY{o}{=}\PY{n}{svae}\PY{p}{,}
    \PY{n}{z0}\PY{o}{=}\PY{n}{z0}\PY{p}{,}
    \PY{n}{uncertainty\PYZus{}weight}\PY{o}{=}\PY{l+m+mf}{1.0}\PY{p}{,}
    \PY{n}{distance\PYZus{}weight}\PY{o}{=}\PY{l+m+mf}{0.01}\PY{p}{,}
    \PY{n}{lr}\PY{o}{=}\PY{l+m+mf}{0.1}\PY{p}{,}
    \PY{n}{device}\PY{o}{=}\PY{n}{device}
\PY{p}{)}

\PY{c+c1}{\PYZsh{} Optimize to find explanation}
\PY{n}{z\PYZus{}explained} \PY{o}{=} \PY{n}{clue}\PY{o}{.}\PY{n}{optimize}\PY{p}{(}\PY{n}{steps}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Generate reconstructions using decoder}
\PY{k}{with} \PY{n}{torch}\PY{o}{.}\PY{n}{no\PYZus{}grad}\PY{p}{(}\PY{p}{)}\PY{p}{:}
    \PY{c+c1}{\PYZsh{} Original reconstruction}
    \PY{n}{original\PYZus{}recon} \PY{o}{=} \PY{n}{svae}\PY{o}{.}\PY{n}{decode}\PY{p}{(}\PY{n}{z0}\PY{p}{)}
    \PY{c+c1}{\PYZsh{} CLUE reconstruction  }
    \PY{n}{clue\PYZus{}recon} \PY{o}{=} \PY{n}{svae}\PY{o}{.}\PY{n}{decode}\PY{p}{(}\PY{n}{z\PYZus{}explained}\PY{p}{)}
    
    \PY{c+c1}{\PYZsh{} Get predictions and uncertainties}
    \PY{c+c1}{\PYZsh{} Use only the classifier head for the latent vectors}
    \PY{n}{original\PYZus{}logits} \PY{o}{=} \PY{n}{svae}\PY{o}{.}\PY{n}{classifier}\PY{p}{(}\PY{n}{z0}\PY{p}{)}
    \PY{n}{explained\PYZus{}logits} \PY{o}{=} \PY{n}{svae}\PY{o}{.}\PY{n}{classifier}\PY{p}{(}\PY{n}{z\PYZus{}explained}\PY{p}{)}
    
    \PY{n}{original\PYZus{}probs} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{functional}\PY{o}{.}\PY{n}{softmax}\PY{p}{(}\PY{n}{original\PYZus{}logits}\PY{p}{,} \PY{n}{dim}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
    \PY{n}{explained\PYZus{}probs} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{functional}\PY{o}{.}\PY{n}{softmax}\PY{p}{(}\PY{n}{explained\PYZus{}logits}\PY{p}{,} \PY{n}{dim}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
    
    \PY{n}{original\PYZus{}entropy} \PY{o}{=} \PY{o}{\PYZhy{}}\PY{p}{(}\PY{n}{original\PYZus{}probs} \PY{o}{*} \PY{n}{torch}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{original\PYZus{}probs} \PY{o}{+} \PY{l+m+mf}{1e\PYZhy{}10}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}
    \PY{n}{explained\PYZus{}entropy} \PY{o}{=} \PY{o}{\PYZhy{}}\PY{p}{(}\PY{n}{explained\PYZus{}probs} \PY{o}{*} \PY{n}{torch}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{explained\PYZus{}probs} \PY{o}{+} \PY{l+m+mf}{1e\PYZhy{}10}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Plot results}
\PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{15}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{)}\PY{p}{)}

\PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{231}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{uncertain\PYZus{}image}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{cpu}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gray}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Original Image}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{Entropy: }\PY{l+s+si}{\PYZob{}}\PY{n}{original\PYZus{}entropy}\PY{l+s+si}{:}\PY{l+s+s1}{.3f}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{axis}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{off}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

\PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{232}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{clue\PYZus{}recon}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{cpu}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{detach}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gray}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Counterfactual}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{Entropy: }\PY{l+s+si}{\PYZob{}}\PY{n}{explained\PYZus{}entropy}\PY{l+s+si}{:}\PY{l+s+s1}{.3f}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{axis}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{off}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

\PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{233}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{torch}\PY{o}{.}\PY{n}{abs}\PY{p}{(}\PY{n}{uncertain\PYZus{}image}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{cpu}\PY{p}{(}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{n}{clue\PYZus{}recon}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{cpu}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{detach}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gray}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Original vs Counterfactual}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{Difference}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{axis}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{off}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

\PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{234}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{original\PYZus{}recon}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{cpu}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{detach}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gray}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Original Reconstruction}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{axis}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{off}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

\PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{235}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{torch}\PY{o}{.}\PY{n}{abs}\PY{p}{(}\PY{n}{original\PYZus{}recon}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{cpu}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{detach}\PY{p}{(}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{n}{clue\PYZus{}recon}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{cpu}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{detach}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gray}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Original vs Counterfactual}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{Reconstruction Difference}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{axis}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{off}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

\PY{n}{plt}\PY{o}{.}\PY{n}{tight\PYZus{}layout}\PY{p}{(}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Print probabilities}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{Class probabilities:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Original:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{original\PYZus{}probs}\PY{o}{.}\PY{n}{cpu}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{numpy}\PY{p}{(}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{round}\PY{p}{(}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Explained:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{explained\PYZus{}probs}\PY{o}{.}\PY{n}{cpu}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{numpy}\PY{p}{(}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{round}\PY{p}{(}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Step 00: Loss: 1.3121, Entropy: 1.3121, Distance: 0.0000
Step 01: Loss: 0.4881, Entropy: 0.4721, Distance: 1.6000
Step 02: Loss: 0.1034, Entropy: 0.0750, Distance: 2.8398
Step 03: Loss: 0.0517, Entropy: 0.0122, Distance: 3.9528
Step 04: Loss: 0.0512, Entropy: 0.0026, Distance: 4.8650
Step 05: Loss: 0.0568, Entropy: 0.0007, Distance: 5.6085
Step 06: Loss: 0.0624, Entropy: 0.0002, Distance: 6.2169
Step 07: Loss: 0.0673, Entropy: 0.0001, Distance: 6.7156
Step 08: Loss: 0.0713, Entropy: 0.0000, Distance: 7.1234
Step 09: Loss: 0.0746, Entropy: 0.0000, Distance: 7.4546
Step 10: Loss: 0.0772, Entropy: 0.0000, Distance: 7.7202
Step 11: Loss: 0.0793, Entropy: 0.0000, Distance: 7.9292
Step 12: Loss: 0.0809, Entropy: 0.0000, Distance: 8.0888
Step 13: Loss: 0.0821, Entropy: 0.0000, Distance: 8.2051
Step 14: Loss: 0.0828, Entropy: 0.0000, Distance: 8.2830
Step 15: Loss: 0.0833, Entropy: 0.0000, Distance: 8.3272
Step 16: Loss: 0.0834, Entropy: 0.0000, Distance: 8.3412
Step 17: Loss: 0.0833, Entropy: 0.0000, Distance: 8.3284
Step 18: Loss: 0.0829, Entropy: 0.0000, Distance: 8.2919
Step 19: Loss: 0.0823, Entropy: 0.0000, Distance: 8.2342
Step 20: Loss: 0.0816, Entropy: 0.0000, Distance: 8.1577
Step 21: Loss: 0.0806, Entropy: 0.0000, Distance: 8.0648
Step 22: Loss: 0.0796, Entropy: 0.0000, Distance: 7.9572
Step 23: Loss: 0.0784, Entropy: 0.0000, Distance: 7.8371
Step 24: Loss: 0.0771, Entropy: 0.0000, Distance: 7.7060
Step 25: Loss: 0.0757, Entropy: 0.0000, Distance: 7.5657
Step 26: Loss: 0.0742, Entropy: 0.0000, Distance: 7.4175
Step 27: Loss: 0.0726, Entropy: 0.0000, Distance: 7.2630
Step 28: Loss: 0.0710, Entropy: 0.0000, Distance: 7.1033
Step 29: Loss: 0.0694, Entropy: 0.0000, Distance: 6.9398
Step 30: Loss: 0.0677, Entropy: 0.0000, Distance: 6.7736
Step 31: Loss: 0.0661, Entropy: 0.0000, Distance: 6.6057
Step 32: Loss: 0.0644, Entropy: 0.0000, Distance: 6.4371
Step 33: Loss: 0.0627, Entropy: 0.0000, Distance: 6.2687
Step 34: Loss: 0.0610, Entropy: 0.0000, Distance: 6.1013
Step 35: Loss: 0.0594, Entropy: 0.0000, Distance: 5.9357
Step 36: Loss: 0.0577, Entropy: 0.0000, Distance: 5.7725
Step 37: Loss: 0.0561, Entropy: 0.0000, Distance: 5.6124
Step 38: Loss: 0.0546, Entropy: 0.0000, Distance: 5.4560
Step 39: Loss: 0.0530, Entropy: 0.0000, Distance: 5.3038
Step 40: Loss: 0.0516, Entropy: 0.0000, Distance: 5.1562
Step 41: Loss: 0.0501, Entropy: 0.0000, Distance: 5.0137
Step 42: Loss: 0.0488, Entropy: 0.0000, Distance: 4.8766
Step 43: Loss: 0.0475, Entropy: 0.0000, Distance: 4.7453
Step 44: Loss: 0.0462, Entropy: 0.0000, Distance: 4.6200
Step 45: Loss: 0.0450, Entropy: 0.0000, Distance: 4.5008
Step 46: Loss: 0.0439, Entropy: 0.0000, Distance: 4.3878
Step 47: Loss: 0.0428, Entropy: 0.0000, Distance: 4.2810
Step 48: Loss: 0.0418, Entropy: 0.0000, Distance: 4.1802
Step 49: Loss: 0.0409, Entropy: 0.0000, Distance: 4.0854
Step 50: Loss: 0.0400, Entropy: 0.0000, Distance: 3.9963
Step 51: Loss: 0.0391, Entropy: 0.0000, Distance: 3.9127
Step 52: Loss: 0.0384, Entropy: 0.0000, Distance: 3.8344
Step 53: Loss: 0.0376, Entropy: 0.0000, Distance: 3.7611
Step 54: Loss: 0.0369, Entropy: 0.0000, Distance: 3.6924
Step 55: Loss: 0.0363, Entropy: 0.0000, Distance: 3.6281
Step 56: Loss: 0.0357, Entropy: 0.0000, Distance: 3.5677
Step 57: Loss: 0.0351, Entropy: 0.0000, Distance: 3.5111
Step 58: Loss: 0.0346, Entropy: 0.0000, Distance: 3.4577
Step 59: Loss: 0.0341, Entropy: 0.0000, Distance: 3.4074
Step 60: Loss: 0.0336, Entropy: 0.0000, Distance: 3.3598
Step 61: Loss: 0.0332, Entropy: 0.0001, Distance: 3.3146
Step 62: Loss: 0.0328, Entropy: 0.0001, Distance: 3.2717
Step 63: Loss: 0.0324, Entropy: 0.0001, Distance: 3.2307
Step 64: Loss: 0.0320, Entropy: 0.0001, Distance: 3.1916
Step 65: Loss: 0.0316, Entropy: 0.0001, Distance: 3.1541
Step 66: Loss: 0.0313, Entropy: 0.0001, Distance: 3.1180
Step 67: Loss: 0.0309, Entropy: 0.0001, Distance: 3.0832
Step 68: Loss: 0.0306, Entropy: 0.0001, Distance: 3.0496
Step 69: Loss: 0.0303, Entropy: 0.0001, Distance: 3.0171
Step 70: Loss: 0.0300, Entropy: 0.0001, Distance: 2.9854
Step 71: Loss: 0.0297, Entropy: 0.0001, Distance: 2.9546
Step 72: Loss: 0.0294, Entropy: 0.0001, Distance: 2.9244
Step 73: Loss: 0.0291, Entropy: 0.0001, Distance: 2.8949
Step 74: Loss: 0.0288, Entropy: 0.0002, Distance: 2.8660
Step 75: Loss: 0.0285, Entropy: 0.0002, Distance: 2.8374
Step 76: Loss: 0.0283, Entropy: 0.0002, Distance: 2.8093
Step 77: Loss: 0.0280, Entropy: 0.0002, Distance: 2.7815
Step 78: Loss: 0.0277, Entropy: 0.0002, Distance: 2.7539
Step 79: Loss: 0.0275, Entropy: 0.0002, Distance: 2.7266
Step 80: Loss: 0.0272, Entropy: 0.0002, Distance: 2.6995
Step 81: Loss: 0.0270, Entropy: 0.0002, Distance: 2.6726
Step 82: Loss: 0.0267, Entropy: 0.0003, Distance: 2.6460
Step 83: Loss: 0.0265, Entropy: 0.0003, Distance: 2.6195
Step 84: Loss: 0.0262, Entropy: 0.0003, Distance: 2.5932
Step 85: Loss: 0.0260, Entropy: 0.0003, Distance: 2.5672
Step 86: Loss: 0.0257, Entropy: 0.0003, Distance: 2.5413
Step 87: Loss: 0.0255, Entropy: 0.0003, Distance: 2.5158
Step 88: Loss: 0.0253, Entropy: 0.0004, Distance: 2.4905
Step 89: Loss: 0.0250, Entropy: 0.0004, Distance: 2.4654
Step 90: Loss: 0.0248, Entropy: 0.0004, Distance: 2.4407
Step 91: Loss: 0.0246, Entropy: 0.0004, Distance: 2.4162
Step 92: Loss: 0.0244, Entropy: 0.0005, Distance: 2.3921
Step 93: Loss: 0.0242, Entropy: 0.0005, Distance: 2.3683
Step 94: Loss: 0.0240, Entropy: 0.0005, Distance: 2.3449
Step 95: Loss: 0.0238, Entropy: 0.0006, Distance: 2.3218
Step 96: Loss: 0.0236, Entropy: 0.0006, Distance: 2.2991
Step 97: Loss: 0.0234, Entropy: 0.0007, Distance: 2.2768
Step 98: Loss: 0.0233, Entropy: 0.0007, Distance: 2.2549
Step 99: Loss: 0.0231, Entropy: 0.0008, Distance: 2.2335
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{test-new-clue_files/test-new-clue_31_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]

Class probabilities:
Original: [0.    0.038 0.    0.    0.204 0.    0.    0.267 0.05  0.441]
Explained: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
    \end{Verbatim}

    Multiple CLUEs

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{12}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Get 20 most uncertain images and generate CLUEs for each}
\PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{20}\PY{p}{,} \PY{l+m+mi}{80}\PY{p}{)}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Increased height significantly to give more space per row}

\PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{20}\PY{p}{)}\PY{p}{:}
    \PY{c+c1}{\PYZsh{} Get uncertain image and its latent representation }
    \PY{n}{uncertain\PYZus{}idx} \PY{o}{=} \PY{n}{sorted\PYZus{}data\PYZus{}indices\PYZus{}svae}\PY{p}{[}\PY{n}{i}\PY{p}{]}
    \PY{n}{uncertain\PYZus{}image}\PY{p}{,} \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{trainset}\PY{p}{[}\PY{n}{uncertain\PYZus{}idx}\PY{p}{]}
    \PY{n}{uncertain\PYZus{}image} \PY{o}{=} \PY{n}{uncertain\PYZus{}image}\PY{o}{.}\PY{n}{to}\PY{p}{(}\PY{n}{device}\PY{p}{)}\PY{o}{.}\PY{n}{unsqueeze}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Get latent representation}
    \PY{n}{svae}\PY{o}{.}\PY{n}{eval}\PY{p}{(}\PY{p}{)}
    \PY{k}{with} \PY{n}{torch}\PY{o}{.}\PY{n}{no\PYZus{}grad}\PY{p}{(}\PY{p}{)}\PY{p}{:}
        \PY{n}{\PYZus{}}\PY{p}{,} \PY{n}{\PYZus{}}\PY{p}{,} \PY{n}{mu}\PY{p}{,} \PY{n}{log\PYZus{}var} \PY{o}{=} \PY{n}{svae}\PY{p}{(}\PY{n}{uncertain\PYZus{}image}\PY{p}{)}
        \PY{n}{z0} \PY{o}{=} \PY{n}{svae}\PY{o}{.}\PY{n}{reparameterize}\PY{p}{(}\PY{n}{mu}\PY{p}{,} \PY{n}{log\PYZus{}var}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Initialize and run CLUE}
    \PY{n}{clue} \PY{o}{=} \PY{n}{new\PYZus{}CLUE}\PY{o}{.}\PY{n}{SimpleCLUE}\PY{p}{(}
        \PY{n}{model}\PY{o}{=}\PY{n}{svae}\PY{p}{,}
        \PY{n}{z0}\PY{o}{=}\PY{n}{z0}\PY{p}{,}
        \PY{n}{uncertainty\PYZus{}weight}\PY{o}{=}\PY{l+m+mf}{1.0}\PY{p}{,}
        \PY{n}{distance\PYZus{}weight}\PY{o}{=}\PY{l+m+mf}{0.02}\PY{p}{,}
        \PY{n}{lr}\PY{o}{=}\PY{l+m+mf}{0.1}\PY{p}{,}
        \PY{n}{device}\PY{o}{=}\PY{n}{device}
    \PY{p}{)}
    \PY{n}{z\PYZus{}explained} \PY{o}{=} \PY{n}{clue}\PY{o}{.}\PY{n}{optimize}\PY{p}{(}\PY{n}{steps}\PY{o}{=}\PY{l+m+mi}{50}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Generate reconstructions}
    \PY{k}{with} \PY{n}{torch}\PY{o}{.}\PY{n}{no\PYZus{}grad}\PY{p}{(}\PY{p}{)}\PY{p}{:}
        \PY{n}{original\PYZus{}recon} \PY{o}{=} \PY{n}{svae}\PY{o}{.}\PY{n}{decode}\PY{p}{(}\PY{n}{z0}\PY{p}{)}
        \PY{n}{clue\PYZus{}recon} \PY{o}{=} \PY{n}{svae}\PY{o}{.}\PY{n}{decode}\PY{p}{(}\PY{n}{z\PYZus{}explained}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Get predictions and uncertainties}
        \PY{n}{original\PYZus{}logits} \PY{o}{=} \PY{n}{svae}\PY{o}{.}\PY{n}{classifier}\PY{p}{(}\PY{n}{z0}\PY{p}{)}
        \PY{n}{explained\PYZus{}logits} \PY{o}{=} \PY{n}{svae}\PY{o}{.}\PY{n}{classifier}\PY{p}{(}\PY{n}{z\PYZus{}explained}\PY{p}{)}
        \PY{n}{original\PYZus{}probs} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{functional}\PY{o}{.}\PY{n}{softmax}\PY{p}{(}\PY{n}{original\PYZus{}logits}\PY{p}{,} \PY{n}{dim}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
        \PY{n}{explained\PYZus{}probs} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{functional}\PY{o}{.}\PY{n}{softmax}\PY{p}{(}\PY{n}{explained\PYZus{}logits}\PY{p}{,} \PY{n}{dim}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
        \PY{n}{original\PYZus{}entropy} \PY{o}{=} \PY{o}{\PYZhy{}}\PY{p}{(}\PY{n}{original\PYZus{}probs} \PY{o}{*} \PY{n}{torch}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{original\PYZus{}probs} \PY{o}{+} \PY{l+m+mf}{1e\PYZhy{}10}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}
        \PY{n}{explained\PYZus{}entropy} \PY{o}{=} \PY{o}{\PYZhy{}}\PY{p}{(}\PY{n}{explained\PYZus{}probs} \PY{o}{*} \PY{n}{torch}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{explained\PYZus{}probs} \PY{o}{+} \PY{l+m+mf}{1e\PYZhy{}10}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Get predicted classes}
        \PY{n}{original\PYZus{}class} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{argmax}\PY{p}{(}\PY{n}{original\PYZus{}probs}\PY{p}{)}\PY{o}{.}\PY{n}{item}\PY{p}{(}\PY{p}{)}
        \PY{n}{explained\PYZus{}class} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{argmax}\PY{p}{(}\PY{n}{explained\PYZus{}probs}\PY{p}{)}\PY{o}{.}\PY{n}{item}\PY{p}{(}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Plot this example}
    \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{20}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{,} \PY{l+m+mi}{3}\PY{o}{*}\PY{n}{i}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)}
    \PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{uncertain\PYZus{}image}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{cpu}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gray}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Original (Class }\PY{l+s+si}{\PYZob{}}\PY{n}{original\PYZus{}class}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s1}{)}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{H=}\PY{l+s+si}{\PYZob{}}\PY{n}{original\PYZus{}entropy}\PY{l+s+si}{:}\PY{l+s+s1}{.2f}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}
    \PY{n}{plt}\PY{o}{.}\PY{n}{axis}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{off}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

    \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{20}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{,} \PY{l+m+mi}{3}\PY{o}{*}\PY{n}{i}\PY{o}{+}\PY{l+m+mi}{2}\PY{p}{)}
    \PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{original\PYZus{}recon}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{cpu}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{detach}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gray}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Reconstruction}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}
    \PY{n}{plt}\PY{o}{.}\PY{n}{axis}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{off}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

    \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{20}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{,} \PY{l+m+mi}{3}\PY{o}{*}\PY{n}{i}\PY{o}{+}\PY{l+m+mi}{3}\PY{p}{)}
    \PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{clue\PYZus{}recon}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{cpu}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{detach}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gray}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{CLUE (Class }\PY{l+s+si}{\PYZob{}}\PY{n}{explained\PYZus{}class}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s1}{)}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{H=}\PY{l+s+si}{\PYZob{}}\PY{n}{explained\PYZus{}entropy}\PY{l+s+si}{:}\PY{l+s+s1}{.2f}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}
    \PY{n}{plt}\PY{o}{.}\PY{n}{axis}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{off}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

\PY{n}{plt}\PY{o}{.}\PY{n}{tight\PYZus{}layout}\PY{p}{(}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Print probabilities for last example}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{Class probabilities for last example:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Original (Class }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{):}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{original\PYZus{}class}\PY{p}{)}\PY{p}{,} \PY{n}{original\PYZus{}probs}\PY{o}{.}\PY{n}{cpu}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{numpy}\PY{p}{(}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{round}\PY{p}{(}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Explained (Class }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{):}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{explained\PYZus{}class}\PY{p}{)}\PY{p}{,} \PY{n}{explained\PYZus{}probs}\PY{o}{.}\PY{n}{cpu}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{numpy}\PY{p}{(}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{round}\PY{p}{(}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Step 00: Loss: 1.5492, Entropy: 1.5492, Distance: 0.0000
Step 01: Loss: 0.9831, Entropy: 0.9511, Distance: 1.6000
Step 02: Loss: 0.5425, Entropy: 0.4860, Distance: 2.8262
Step 03: Loss: 0.1684, Entropy: 0.0942, Distance: 3.7123
Step 04: Loss: 0.1043, Entropy: 0.0135, Distance: 4.5408
Step 05: Loss: 0.1072, Entropy: 0.0023, Distance: 5.2434
Step 06: Loss: 0.1169, Entropy: 0.0005, Distance: 5.8178
Step 07: Loss: 0.1257, Entropy: 0.0001, Distance: 6.2796
Step 08: Loss: 0.1330, Entropy: 0.0001, Distance: 6.6452
Step 09: Loss: 0.1386, Entropy: 0.0000, Distance: 6.9283
Step 10: Loss: 0.1428, Entropy: 0.0000, Distance: 7.1407
Step 11: Loss: 0.1458, Entropy: 0.0000, Distance: 7.2918
Step 12: Loss: 0.1478, Entropy: 0.0000, Distance: 7.3898
Step 13: Loss: 0.1488, Entropy: 0.0000, Distance: 7.4415
Step 14: Loss: 0.1491, Entropy: 0.0000, Distance: 7.4530
Step 15: Loss: 0.1486, Entropy: 0.0000, Distance: 7.4294
Step 16: Loss: 0.1475, Entropy: 0.0000, Distance: 7.3753
Step 17: Loss: 0.1459, Entropy: 0.0000, Distance: 7.2948
Step 18: Loss: 0.1438, Entropy: 0.0000, Distance: 7.1914
Step 19: Loss: 0.1414, Entropy: 0.0000, Distance: 7.0683
Step 20: Loss: 0.1386, Entropy: 0.0000, Distance: 6.9287
Step 21: Loss: 0.1355, Entropy: 0.0000, Distance: 6.7752
Step 22: Loss: 0.1322, Entropy: 0.0000, Distance: 6.6103
Step 23: Loss: 0.1287, Entropy: 0.0000, Distance: 6.4366
Step 24: Loss: 0.1251, Entropy: 0.0000, Distance: 6.2564
Step 25: Loss: 0.1214, Entropy: 0.0000, Distance: 6.0718
Step 26: Loss: 0.1177, Entropy: 0.0000, Distance: 5.8852
Step 27: Loss: 0.1140, Entropy: 0.0000, Distance: 5.6984
Step 28: Loss: 0.1103, Entropy: 0.0000, Distance: 5.5135
Step 29: Loss: 0.1066, Entropy: 0.0000, Distance: 5.3321
Step 30: Loss: 0.1031, Entropy: 0.0000, Distance: 5.1559
Step 31: Loss: 0.0997, Entropy: 0.0000, Distance: 4.9864
Step 32: Loss: 0.0965, Entropy: 0.0000, Distance: 4.8246
Step 33: Loss: 0.0934, Entropy: 0.0000, Distance: 4.6718
Step 34: Loss: 0.0906, Entropy: 0.0000, Distance: 4.5286
Step 35: Loss: 0.0879, Entropy: 0.0000, Distance: 4.3956
Step 36: Loss: 0.0855, Entropy: 0.0000, Distance: 4.2732
Step 37: Loss: 0.0832, Entropy: 0.0000, Distance: 4.1613
Step 38: Loss: 0.0812, Entropy: 0.0000, Distance: 4.0596
Step 39: Loss: 0.0794, Entropy: 0.0000, Distance: 3.9676
Step 40: Loss: 0.0777, Entropy: 0.0000, Distance: 3.8844
Step 41: Loss: 0.0762, Entropy: 0.0000, Distance: 3.8092
Step 42: Loss: 0.0749, Entropy: 0.0000, Distance: 3.7407
Step 43: Loss: 0.0736, Entropy: 0.0001, Distance: 3.6780
Step 44: Loss: 0.0725, Entropy: 0.0001, Distance: 3.6199
Step 45: Loss: 0.0714, Entropy: 0.0001, Distance: 3.5654
Step 46: Loss: 0.0704, Entropy: 0.0001, Distance: 3.5138
Step 47: Loss: 0.0694, Entropy: 0.0001, Distance: 3.4644
Step 48: Loss: 0.0684, Entropy: 0.0001, Distance: 3.4168
Step 49: Loss: 0.0675, Entropy: 0.0001, Distance: 3.3706
Step 00: Loss: 1.4458, Entropy: 1.4458, Distance: 0.0000
Step 01: Loss: 0.5014, Entropy: 0.4694, Distance: 1.5998
Step 02: Loss: 0.1128, Entropy: 0.0543, Distance: 2.9234
Step 03: Loss: 0.0868, Entropy: 0.0074, Distance: 3.9713
Step 04: Loss: 0.0964, Entropy: 0.0014, Distance: 4.7492
Step 05: Loss: 0.1069, Entropy: 0.0004, Distance: 5.3268
Step 06: Loss: 0.1152, Entropy: 0.0001, Distance: 5.7533
Step 07: Loss: 0.1213, Entropy: 0.0000, Distance: 6.0621
Step 08: Loss: 0.1256, Entropy: 0.0000, Distance: 6.2768
Step 09: Loss: 0.1283, Entropy: 0.0000, Distance: 6.4149
Step 10: Loss: 0.1298, Entropy: 0.0000, Distance: 6.4902
Step 11: Loss: 0.1303, Entropy: 0.0000, Distance: 6.5132
Step 12: Loss: 0.1299, Entropy: 0.0000, Distance: 6.4927
Step 13: Loss: 0.1287, Entropy: 0.0000, Distance: 6.4362
Step 14: Loss: 0.1270, Entropy: 0.0000, Distance: 6.3500
Step 15: Loss: 0.1248, Entropy: 0.0000, Distance: 6.2398
Step 16: Loss: 0.1222, Entropy: 0.0000, Distance: 6.1105
Step 17: Loss: 0.1193, Entropy: 0.0000, Distance: 5.9667
Step 18: Loss: 0.1162, Entropy: 0.0000, Distance: 5.8124
Step 19: Loss: 0.1130, Entropy: 0.0000, Distance: 5.6511
Step 20: Loss: 0.1097, Entropy: 0.0000, Distance: 5.4857
Step 21: Loss: 0.1064, Entropy: 0.0000, Distance: 5.3188
Step 22: Loss: 0.1030, Entropy: 0.0000, Distance: 5.1523
Step 23: Loss: 0.0998, Entropy: 0.0000, Distance: 4.9877
Step 24: Loss: 0.0965, Entropy: 0.0000, Distance: 4.8265
Step 25: Loss: 0.0934, Entropy: 0.0000, Distance: 4.6698
Step 26: Loss: 0.0904, Entropy: 0.0000, Distance: 4.5185
Step 27: Loss: 0.0875, Entropy: 0.0000, Distance: 4.3738
Step 28: Loss: 0.0847, Entropy: 0.0000, Distance: 4.2362
Step 29: Loss: 0.0821, Entropy: 0.0000, Distance: 4.1066
Step 30: Loss: 0.0797, Entropy: 0.0000, Distance: 3.9854
Step 31: Loss: 0.0775, Entropy: 0.0000, Distance: 3.8731
Step 32: Loss: 0.0754, Entropy: 0.0000, Distance: 3.7697
Step 33: Loss: 0.0735, Entropy: 0.0000, Distance: 3.6750
Step 34: Loss: 0.0718, Entropy: 0.0000, Distance: 3.5888
Step 35: Loss: 0.0702, Entropy: 0.0000, Distance: 3.5107
Step 36: Loss: 0.0688, Entropy: 0.0000, Distance: 3.4403
Step 37: Loss: 0.0675, Entropy: 0.0000, Distance: 3.3768
Step 38: Loss: 0.0664, Entropy: 0.0000, Distance: 3.3195
Step 39: Loss: 0.0654, Entropy: 0.0000, Distance: 3.2676
Step 40: Loss: 0.0644, Entropy: 0.0000, Distance: 3.2200
Step 41: Loss: 0.0635, Entropy: 0.0000, Distance: 3.1757
Step 42: Loss: 0.0627, Entropy: 0.0000, Distance: 3.1339
Step 43: Loss: 0.0619, Entropy: 0.0000, Distance: 3.0937
Step 44: Loss: 0.0611, Entropy: 0.0000, Distance: 3.0545
Step 45: Loss: 0.0603, Entropy: 0.0000, Distance: 3.0158
Step 46: Loss: 0.0596, Entropy: 0.0000, Distance: 2.9772
Step 47: Loss: 0.0588, Entropy: 0.0000, Distance: 2.9385
Step 48: Loss: 0.0580, Entropy: 0.0000, Distance: 2.8997
Step 49: Loss: 0.0573, Entropy: 0.0000, Distance: 2.8608
Step 00: Loss: 0.8512, Entropy: 0.8512, Distance: 0.0000
Step 01: Loss: 0.1211, Entropy: 0.0891, Distance: 1.6000
Step 02: Loss: 0.0648, Entropy: 0.0114, Distance: 2.6719
Step 03: Loss: 0.0710, Entropy: 0.0023, Distance: 3.4356
Step 04: Loss: 0.0805, Entropy: 0.0007, Distance: 3.9943
Step 05: Loss: 0.0884, Entropy: 0.0002, Distance: 4.4059
Step 06: Loss: 0.0942, Entropy: 0.0001, Distance: 4.7070
Step 07: Loss: 0.0985, Entropy: 0.0001, Distance: 4.9220
Step 08: Loss: 0.1014, Entropy: 0.0000, Distance: 5.0688
Step 09: Loss: 0.1032, Entropy: 0.0000, Distance: 5.1607
Step 10: Loss: 0.1042, Entropy: 0.0000, Distance: 5.2081
Step 11: Loss: 0.1044, Entropy: 0.0000, Distance: 5.2190
Step 12: Loss: 0.1040, Entropy: 0.0000, Distance: 5.2000
Step 13: Loss: 0.1031, Entropy: 0.0000, Distance: 5.1563
Step 14: Loss: 0.1019, Entropy: 0.0000, Distance: 5.0922
Step 15: Loss: 0.1002, Entropy: 0.0000, Distance: 5.0113
Step 16: Loss: 0.0983, Entropy: 0.0000, Distance: 4.9168
Step 17: Loss: 0.0962, Entropy: 0.0000, Distance: 4.8112
Step 18: Loss: 0.0939, Entropy: 0.0000, Distance: 4.6969
Step 19: Loss: 0.0915, Entropy: 0.0000, Distance: 4.5760
Step 20: Loss: 0.0890, Entropy: 0.0000, Distance: 4.4504
Step 21: Loss: 0.0864, Entropy: 0.0000, Distance: 4.3217
Step 22: Loss: 0.0838, Entropy: 0.0000, Distance: 4.1915
Step 23: Loss: 0.0812, Entropy: 0.0000, Distance: 4.0609
Step 24: Loss: 0.0786, Entropy: 0.0000, Distance: 3.9310
Step 25: Loss: 0.0761, Entropy: 0.0000, Distance: 3.8031
Step 26: Loss: 0.0736, Entropy: 0.0000, Distance: 3.6783
Step 27: Loss: 0.0712, Entropy: 0.0000, Distance: 3.5580
Step 28: Loss: 0.0689, Entropy: 0.0000, Distance: 3.4434
Step 29: Loss: 0.0667, Entropy: 0.0000, Distance: 3.3355
Step 30: Loss: 0.0647, Entropy: 0.0000, Distance: 3.2349
Step 31: Loss: 0.0629, Entropy: 0.0000, Distance: 3.1418
Step 32: Loss: 0.0611, Entropy: 0.0000, Distance: 3.0562
Step 33: Loss: 0.0596, Entropy: 0.0000, Distance: 2.9780
Step 34: Loss: 0.0582, Entropy: 0.0000, Distance: 2.9069
Step 35: Loss: 0.0569, Entropy: 0.0000, Distance: 2.8424
Step 36: Loss: 0.0557, Entropy: 0.0000, Distance: 2.7836
Step 37: Loss: 0.0546, Entropy: 0.0000, Distance: 2.7299
Step 38: Loss: 0.0536, Entropy: 0.0000, Distance: 2.6808
Step 39: Loss: 0.0527, Entropy: 0.0000, Distance: 2.6356
Step 40: Loss: 0.0519, Entropy: 0.0000, Distance: 2.5942
Step 41: Loss: 0.0512, Entropy: 0.0000, Distance: 2.5557
Step 42: Loss: 0.0504, Entropy: 0.0000, Distance: 2.5194
Step 43: Loss: 0.0497, Entropy: 0.0001, Distance: 2.4844
Step 44: Loss: 0.0491, Entropy: 0.0001, Distance: 2.4501
Step 45: Loss: 0.0484, Entropy: 0.0001, Distance: 2.4162
Step 46: Loss: 0.0477, Entropy: 0.0001, Distance: 2.3821
Step 47: Loss: 0.0470, Entropy: 0.0001, Distance: 2.3479
Step 48: Loss: 0.0463, Entropy: 0.0001, Distance: 2.3134
Step 49: Loss: 0.0457, Entropy: 0.0001, Distance: 2.2788
Step 00: Loss: 1.2270, Entropy: 1.2270, Distance: 0.0000
Step 01: Loss: 0.3184, Entropy: 0.2864, Distance: 1.6000
Step 02: Loss: 0.0806, Entropy: 0.0231, Distance: 2.8749
Step 03: Loss: 0.0796, Entropy: 0.0030, Distance: 3.8335
Step 04: Loss: 0.0913, Entropy: 0.0006, Distance: 4.5331
Step 05: Loss: 0.1010, Entropy: 0.0002, Distance: 5.0442
Step 06: Loss: 0.1083, Entropy: 0.0001, Distance: 5.4128
Step 07: Loss: 0.1134, Entropy: 0.0000, Distance: 5.6705
Step 08: Loss: 0.1168, Entropy: 0.0000, Distance: 5.8399
Step 09: Loss: 0.1188, Entropy: 0.0000, Distance: 5.9379
Step 10: Loss: 0.1196, Entropy: 0.0000, Distance: 5.9774
Step 11: Loss: 0.1194, Entropy: 0.0000, Distance: 5.9688
Step 12: Loss: 0.1184, Entropy: 0.0000, Distance: 5.9204
Step 13: Loss: 0.1168, Entropy: 0.0000, Distance: 5.8390
Step 14: Loss: 0.1146, Entropy: 0.0000, Distance: 5.7307
Step 15: Loss: 0.1120, Entropy: 0.0000, Distance: 5.6008
Step 16: Loss: 0.1091, Entropy: 0.0000, Distance: 5.4541
Step 17: Loss: 0.1059, Entropy: 0.0000, Distance: 5.2951
Step 18: Loss: 0.1026, Entropy: 0.0000, Distance: 5.1282
Step 19: Loss: 0.0991, Entropy: 0.0000, Distance: 4.9570
Step 20: Loss: 0.0957, Entropy: 0.0000, Distance: 4.7848
Step 21: Loss: 0.0923, Entropy: 0.0000, Distance: 4.6145
Step 22: Loss: 0.0890, Entropy: 0.0000, Distance: 4.4482
Step 23: Loss: 0.0858, Entropy: 0.0000, Distance: 4.2879
Step 24: Loss: 0.0827, Entropy: 0.0000, Distance: 4.1348
Step 25: Loss: 0.0798, Entropy: 0.0000, Distance: 3.9901
Step 26: Loss: 0.0771, Entropy: 0.0000, Distance: 3.8549
Step 27: Loss: 0.0746, Entropy: 0.0000, Distance: 3.7299
Step 28: Loss: 0.0723, Entropy: 0.0000, Distance: 3.6157
Step 29: Loss: 0.0703, Entropy: 0.0000, Distance: 3.5127
Step 30: Loss: 0.0684, Entropy: 0.0000, Distance: 3.4212
Step 31: Loss: 0.0668, Entropy: 0.0000, Distance: 3.3408
Step 32: Loss: 0.0654, Entropy: 0.0000, Distance: 3.2706
Step 33: Loss: 0.0642, Entropy: 0.0000, Distance: 3.2093
Step 34: Loss: 0.0631, Entropy: 0.0000, Distance: 3.1553
Step 35: Loss: 0.0621, Entropy: 0.0000, Distance: 3.1069
Step 36: Loss: 0.0613, Entropy: 0.0000, Distance: 3.0625
Step 37: Loss: 0.0604, Entropy: 0.0000, Distance: 3.0209
Step 38: Loss: 0.0596, Entropy: 0.0000, Distance: 2.9810
Step 39: Loss: 0.0589, Entropy: 0.0000, Distance: 2.9420
Step 40: Loss: 0.0581, Entropy: 0.0000, Distance: 2.9033
Step 41: Loss: 0.0573, Entropy: 0.0000, Distance: 2.8645
Step 42: Loss: 0.0565, Entropy: 0.0000, Distance: 2.8252
Step 43: Loss: 0.0557, Entropy: 0.0000, Distance: 2.7854
Step 44: Loss: 0.0549, Entropy: 0.0000, Distance: 2.7451
Step 45: Loss: 0.0541, Entropy: 0.0000, Distance: 2.7043
Step 46: Loss: 0.0533, Entropy: 0.0000, Distance: 2.6631
Step 47: Loss: 0.0525, Entropy: 0.0000, Distance: 2.6217
Step 48: Loss: 0.0516, Entropy: 0.0000, Distance: 2.5800
Step 49: Loss: 0.0508, Entropy: 0.0000, Distance: 2.5380
Step 00: Loss: 0.6045, Entropy: 0.6045, Distance: 0.0000
Step 01: Loss: 0.1082, Entropy: 0.0762, Distance: 1.6000
Step 02: Loss: 0.0660, Entropy: 0.0131, Distance: 2.6449
Step 03: Loss: 0.0711, Entropy: 0.0033, Distance: 3.3906
Step 04: Loss: 0.0798, Entropy: 0.0011, Distance: 3.9354
Step 05: Loss: 0.0872, Entropy: 0.0005, Distance: 4.3360
Step 06: Loss: 0.0928, Entropy: 0.0002, Distance: 4.6276
Step 07: Loss: 0.0968, Entropy: 0.0001, Distance: 4.8340
Step 08: Loss: 0.0995, Entropy: 0.0001, Distance: 4.9729
Step 09: Loss: 0.1012, Entropy: 0.0001, Distance: 5.0576
Step 10: Loss: 0.1020, Entropy: 0.0000, Distance: 5.0984
Step 11: Loss: 0.1021, Entropy: 0.0000, Distance: 5.1033
Step 12: Loss: 0.1016, Entropy: 0.0000, Distance: 5.0786
Step 13: Loss: 0.1006, Entropy: 0.0000, Distance: 5.0293
Step 14: Loss: 0.0992, Entropy: 0.0000, Distance: 4.9593
Step 15: Loss: 0.0975, Entropy: 0.0000, Distance: 4.8721
Step 16: Loss: 0.0954, Entropy: 0.0000, Distance: 4.7703
Step 17: Loss: 0.0932, Entropy: 0.0000, Distance: 4.6567
Step 18: Loss: 0.0907, Entropy: 0.0000, Distance: 4.5337
Step 19: Loss: 0.0881, Entropy: 0.0000, Distance: 4.4039
Step 20: Loss: 0.0854, Entropy: 0.0000, Distance: 4.2699
Step 21: Loss: 0.0827, Entropy: 0.0000, Distance: 4.1339
Step 22: Loss: 0.0800, Entropy: 0.0000, Distance: 3.9979
Step 23: Loss: 0.0773, Entropy: 0.0000, Distance: 3.8636
Step 24: Loss: 0.0747, Entropy: 0.0000, Distance: 3.7321
Step 25: Loss: 0.0721, Entropy: 0.0000, Distance: 3.6045
Step 26: Loss: 0.0697, Entropy: 0.0000, Distance: 3.4818
Step 27: Loss: 0.0673, Entropy: 0.0000, Distance: 3.3646
Step 28: Loss: 0.0651, Entropy: 0.0001, Distance: 3.2536
Step 29: Loss: 0.0630, Entropy: 0.0001, Distance: 3.1488
Step 30: Loss: 0.0611, Entropy: 0.0001, Distance: 3.0503
Step 31: Loss: 0.0592, Entropy: 0.0001, Distance: 2.9578
Step 32: Loss: 0.0575, Entropy: 0.0001, Distance: 2.8710
Step 33: Loss: 0.0559, Entropy: 0.0001, Distance: 2.7898
Step 34: Loss: 0.0544, Entropy: 0.0001, Distance: 2.7137
Step 35: Loss: 0.0530, Entropy: 0.0001, Distance: 2.6424
Step 36: Loss: 0.0517, Entropy: 0.0002, Distance: 2.5753
Step 37: Loss: 0.0504, Entropy: 0.0002, Distance: 2.5120
Step 38: Loss: 0.0493, Entropy: 0.0002, Distance: 2.4520
Step 39: Loss: 0.0482, Entropy: 0.0003, Distance: 2.3948
Step 40: Loss: 0.0471, Entropy: 0.0003, Distance: 2.3404
Step 41: Loss: 0.0461, Entropy: 0.0003, Distance: 2.2887
Step 42: Loss: 0.0452, Entropy: 0.0004, Distance: 2.2398
Step 43: Loss: 0.0443, Entropy: 0.0004, Distance: 2.1934
Step 44: Loss: 0.0434, Entropy: 0.0005, Distance: 2.1494
Step 45: Loss: 0.0427, Entropy: 0.0005, Distance: 2.1075
Step 46: Loss: 0.0419, Entropy: 0.0006, Distance: 2.0675
Step 47: Loss: 0.0412, Entropy: 0.0006, Distance: 2.0290
Step 48: Loss: 0.0405, Entropy: 0.0007, Distance: 1.9916
Step 49: Loss: 0.0398, Entropy: 0.0007, Distance: 1.9548
Step 00: Loss: 0.6999, Entropy: 0.6999, Distance: 0.0000
Step 01: Loss: 0.1285, Entropy: 0.0965, Distance: 1.6000
Step 02: Loss: 0.0694, Entropy: 0.0153, Distance: 2.7030
Step 03: Loss: 0.0735, Entropy: 0.0036, Distance: 3.4955
Step 04: Loss: 0.0827, Entropy: 0.0012, Distance: 4.0742
Step 05: Loss: 0.0904, Entropy: 0.0005, Distance: 4.4982
Step 06: Loss: 0.0963, Entropy: 0.0002, Distance: 4.8046
Step 07: Loss: 0.1005, Entropy: 0.0001, Distance: 5.0191
Step 08: Loss: 0.1033, Entropy: 0.0001, Distance: 5.1600
Step 09: Loss: 0.1049, Entropy: 0.0001, Distance: 5.2414
Step 10: Loss: 0.1055, Entropy: 0.0000, Distance: 5.2740
Step 11: Loss: 0.1054, Entropy: 0.0000, Distance: 5.2663
Step 12: Loss: 0.1045, Entropy: 0.0000, Distance: 5.2248
Step 13: Loss: 0.1031, Entropy: 0.0000, Distance: 5.1552
Step 14: Loss: 0.1013, Entropy: 0.0000, Distance: 5.0619
Step 15: Loss: 0.0990, Entropy: 0.0000, Distance: 4.9490
Step 16: Loss: 0.0964, Entropy: 0.0000, Distance: 4.8203
Step 17: Loss: 0.0936, Entropy: 0.0000, Distance: 4.6792
Step 18: Loss: 0.0906, Entropy: 0.0000, Distance: 4.5288
Step 19: Loss: 0.0875, Entropy: 0.0000, Distance: 4.3723
Step 20: Loss: 0.0843, Entropy: 0.0000, Distance: 4.2122
Step 21: Loss: 0.0810, Entropy: 0.0000, Distance: 4.0513
Step 22: Loss: 0.0779, Entropy: 0.0000, Distance: 3.8918
Step 23: Loss: 0.0747, Entropy: 0.0000, Distance: 3.7359
Step 24: Loss: 0.0717, Entropy: 0.0000, Distance: 3.5855
Step 25: Loss: 0.0689, Entropy: 0.0000, Distance: 3.4424
Step 26: Loss: 0.0662, Entropy: 0.0000, Distance: 3.3076
Step 27: Loss: 0.0637, Entropy: 0.0000, Distance: 3.1820
Step 28: Loss: 0.0614, Entropy: 0.0000, Distance: 3.0664
Step 29: Loss: 0.0593, Entropy: 0.0000, Distance: 2.9610
Step 30: Loss: 0.0574, Entropy: 0.0001, Distance: 2.8660
Step 31: Loss: 0.0557, Entropy: 0.0001, Distance: 2.7813
Step 32: Loss: 0.0542, Entropy: 0.0001, Distance: 2.7066
Step 33: Loss: 0.0529, Entropy: 0.0001, Distance: 2.6411
Step 34: Loss: 0.0518, Entropy: 0.0001, Distance: 2.5837
Step 35: Loss: 0.0508, Entropy: 0.0001, Distance: 2.5334
Step 36: Loss: 0.0499, Entropy: 0.0001, Distance: 2.4888
Step 37: Loss: 0.0491, Entropy: 0.0001, Distance: 2.4486
Step 38: Loss: 0.0484, Entropy: 0.0001, Distance: 2.4115
Step 39: Loss: 0.0477, Entropy: 0.0002, Distance: 2.3763
Step 40: Loss: 0.0470, Entropy: 0.0002, Distance: 2.3422
Step 41: Loss: 0.0464, Entropy: 0.0002, Distance: 2.3084
Step 42: Loss: 0.0457, Entropy: 0.0002, Distance: 2.2744
Step 43: Loss: 0.0450, Entropy: 0.0002, Distance: 2.2397
Step 44: Loss: 0.0443, Entropy: 0.0003, Distance: 2.2038
Step 45: Loss: 0.0436, Entropy: 0.0003, Distance: 2.1663
Step 46: Loss: 0.0428, Entropy: 0.0003, Distance: 2.1272
Step 47: Loss: 0.0420, Entropy: 0.0003, Distance: 2.0865
Step 48: Loss: 0.0412, Entropy: 0.0003, Distance: 2.0446
Step 49: Loss: 0.0404, Entropy: 0.0004, Distance: 2.0018
Step 00: Loss: 0.8810, Entropy: 0.8810, Distance: 0.0000
Step 01: Loss: 0.1443, Entropy: 0.1123, Distance: 1.6000
Step 02: Loss: 0.0694, Entropy: 0.0150, Distance: 2.7208
Step 03: Loss: 0.0743, Entropy: 0.0037, Distance: 3.5321
Step 04: Loss: 0.0839, Entropy: 0.0013, Distance: 4.1279
Step 05: Loss: 0.0920, Entropy: 0.0006, Distance: 4.5657
Step 06: Loss: 0.0980, Entropy: 0.0004, Distance: 4.8825
Step 07: Loss: 0.1023, Entropy: 0.0002, Distance: 5.1042
Step 08: Loss: 0.1052, Entropy: 0.0002, Distance: 5.2503
Step 09: Loss: 0.1068, Entropy: 0.0001, Distance: 5.3357
Step 10: Loss: 0.1076, Entropy: 0.0001, Distance: 5.3724
Step 11: Loss: 0.1075, Entropy: 0.0001, Distance: 5.3699
Step 12: Loss: 0.1068, Entropy: 0.0001, Distance: 5.3358
Step 13: Loss: 0.1056, Entropy: 0.0001, Distance: 5.2760
Step 14: Loss: 0.1040, Entropy: 0.0001, Distance: 5.1952
Step 15: Loss: 0.1020, Entropy: 0.0001, Distance: 5.0974
Step 16: Loss: 0.0998, Entropy: 0.0001, Distance: 4.9859
Step 17: Loss: 0.0974, Entropy: 0.0001, Distance: 4.8636
Step 18: Loss: 0.0948, Entropy: 0.0001, Distance: 4.7331
Step 19: Loss: 0.0921, Entropy: 0.0001, Distance: 4.5967
Step 20: Loss: 0.0893, Entropy: 0.0001, Distance: 4.4563
Step 21: Loss: 0.0864, Entropy: 0.0002, Distance: 4.3134
Step 22: Loss: 0.0836, Entropy: 0.0002, Distance: 4.1695
Step 23: Loss: 0.0807, Entropy: 0.0002, Distance: 4.0256
Step 24: Loss: 0.0779, Entropy: 0.0002, Distance: 3.8829
Step 25: Loss: 0.0751, Entropy: 0.0002, Distance: 3.7427
Step 26: Loss: 0.0724, Entropy: 0.0002, Distance: 3.6062
Step 27: Loss: 0.0697, Entropy: 0.0003, Distance: 3.4746
Step 28: Loss: 0.0673, Entropy: 0.0003, Distance: 3.3492
Step 29: Loss: 0.0649, Entropy: 0.0003, Distance: 3.2306
Step 30: Loss: 0.0627, Entropy: 0.0003, Distance: 3.1192
Step 31: Loss: 0.0606, Entropy: 0.0003, Distance: 3.0154
Step 32: Loss: 0.0587, Entropy: 0.0003, Distance: 2.9195
Step 33: Loss: 0.0570, Entropy: 0.0003, Distance: 2.8315
Step 34: Loss: 0.0554, Entropy: 0.0004, Distance: 2.7515
Step 35: Loss: 0.0540, Entropy: 0.0004, Distance: 2.6790
Step 36: Loss: 0.0527, Entropy: 0.0004, Distance: 2.6134
Step 37: Loss: 0.0515, Entropy: 0.0004, Distance: 2.5537
Step 38: Loss: 0.0504, Entropy: 0.0004, Distance: 2.4990
Step 39: Loss: 0.0494, Entropy: 0.0004, Distance: 2.4481
Step 40: Loss: 0.0484, Entropy: 0.0004, Distance: 2.4003
Step 41: Loss: 0.0475, Entropy: 0.0004, Distance: 2.3548
Step 42: Loss: 0.0467, Entropy: 0.0005, Distance: 2.3112
Step 43: Loss: 0.0459, Entropy: 0.0005, Distance: 2.2695
Step 44: Loss: 0.0451, Entropy: 0.0005, Distance: 2.2295
Step 45: Loss: 0.0443, Entropy: 0.0005, Distance: 2.1911
Step 46: Loss: 0.0436, Entropy: 0.0005, Distance: 2.1540
Step 47: Loss: 0.0429, Entropy: 0.0005, Distance: 2.1181
Step 48: Loss: 0.0422, Entropy: 0.0005, Distance: 2.0829
Step 49: Loss: 0.0415, Entropy: 0.0006, Distance: 2.0485
Step 00: Loss: 1.6449, Entropy: 1.6449, Distance: 0.0000
Step 01: Loss: 0.9781, Entropy: 0.9461, Distance: 1.6000
Step 02: Loss: 0.7882, Entropy: 0.7307, Distance: 2.8759
Step 03: Loss: 0.5125, Entropy: 0.4353, Distance: 3.8587
Step 04: Loss: 0.2148, Entropy: 0.1203, Distance: 4.7250
Step 05: Loss: 0.1357, Entropy: 0.0243, Distance: 5.5691
Step 06: Loss: 0.1316, Entropy: 0.0054, Distance: 6.3100
Step 07: Loss: 0.1401, Entropy: 0.0015, Distance: 6.9297
Step 08: Loss: 0.1492, Entropy: 0.0005, Distance: 7.4363
Step 09: Loss: 0.1571, Entropy: 0.0002, Distance: 7.8427
Step 10: Loss: 0.1633, Entropy: 0.0001, Distance: 8.1616
Step 11: Loss: 0.1681, Entropy: 0.0001, Distance: 8.4040
Step 12: Loss: 0.1716, Entropy: 0.0000, Distance: 8.5797
Step 13: Loss: 0.1740, Entropy: 0.0000, Distance: 8.6970
Step 14: Loss: 0.1753, Entropy: 0.0000, Distance: 8.7631
Step 15: Loss: 0.1757, Entropy: 0.0000, Distance: 8.7843
Step 16: Loss: 0.1753, Entropy: 0.0000, Distance: 8.7660
Step 17: Loss: 0.1743, Entropy: 0.0000, Distance: 8.7131
Step 18: Loss: 0.1726, Entropy: 0.0000, Distance: 8.6299
Step 19: Loss: 0.1704, Entropy: 0.0000, Distance: 8.5203
Step 20: Loss: 0.1678, Entropy: 0.0000, Distance: 8.3876
Step 21: Loss: 0.1647, Entropy: 0.0000, Distance: 8.2350
Step 22: Loss: 0.1613, Entropy: 0.0000, Distance: 8.0655
Step 23: Loss: 0.1576, Entropy: 0.0000, Distance: 7.8816
Step 24: Loss: 0.1537, Entropy: 0.0000, Distance: 7.6860
Step 25: Loss: 0.1496, Entropy: 0.0000, Distance: 7.4810
Step 26: Loss: 0.1454, Entropy: 0.0000, Distance: 7.2687
Step 27: Loss: 0.1410, Entropy: 0.0000, Distance: 7.0512
Step 28: Loss: 0.1366, Entropy: 0.0000, Distance: 6.8307
Step 29: Loss: 0.1322, Entropy: 0.0000, Distance: 6.6088
Step 30: Loss: 0.1278, Entropy: 0.0000, Distance: 6.3875
Step 31: Loss: 0.1234, Entropy: 0.0000, Distance: 6.1685
Step 32: Loss: 0.1191, Entropy: 0.0000, Distance: 5.9533
Step 33: Loss: 0.1149, Entropy: 0.0000, Distance: 5.7434
Step 34: Loss: 0.1109, Entropy: 0.0000, Distance: 5.5404
Step 35: Loss: 0.1070, Entropy: 0.0001, Distance: 5.3454
Step 36: Loss: 0.1033, Entropy: 0.0001, Distance: 5.1597
Step 37: Loss: 0.0998, Entropy: 0.0001, Distance: 4.9844
Step 38: Loss: 0.0965, Entropy: 0.0001, Distance: 4.8202
Step 39: Loss: 0.0935, Entropy: 0.0001, Distance: 4.6679
Step 40: Loss: 0.0907, Entropy: 0.0001, Distance: 4.5276
Step 41: Loss: 0.0882, Entropy: 0.0002, Distance: 4.3996
Step 42: Loss: 0.0859, Entropy: 0.0002, Distance: 4.2836
Step 43: Loss: 0.0838, Entropy: 0.0002, Distance: 4.1789
Step 44: Loss: 0.0820, Entropy: 0.0003, Distance: 4.0849
Step 45: Loss: 0.0803, Entropy: 0.0003, Distance: 4.0004
Step 46: Loss: 0.0789, Entropy: 0.0004, Distance: 3.9245
Step 47: Loss: 0.0776, Entropy: 0.0004, Distance: 3.8560
Step 48: Loss: 0.0764, Entropy: 0.0005, Distance: 3.7939
Step 49: Loss: 0.0753, Entropy: 0.0006, Distance: 3.7370
Step 00: Loss: 1.6844, Entropy: 1.6844, Distance: 0.0000
Step 01: Loss: 0.6749, Entropy: 0.6429, Distance: 1.6000
Step 02: Loss: 0.1788, Entropy: 0.1227, Distance: 2.8071
Step 03: Loss: 0.1028, Entropy: 0.0250, Distance: 3.8941
Step 04: Loss: 0.1027, Entropy: 0.0071, Distance: 4.7790
Step 05: Loss: 0.1125, Entropy: 0.0028, Distance: 5.4864
Step 06: Loss: 0.1223, Entropy: 0.0014, Distance: 6.0490
Step 07: Loss: 0.1306, Entropy: 0.0008, Distance: 6.4931
Step 08: Loss: 0.1373, Entropy: 0.0005, Distance: 6.8392
Step 09: Loss: 0.1424, Entropy: 0.0003, Distance: 7.1027
Step 10: Loss: 0.1462, Entropy: 0.0003, Distance: 7.2960
Step 11: Loss: 0.1488, Entropy: 0.0002, Distance: 7.4292
Step 12: Loss: 0.1504, Entropy: 0.0002, Distance: 7.5103
Step 13: Loss: 0.1511, Entropy: 0.0001, Distance: 7.5463
Step 14: Loss: 0.1510, Entropy: 0.0001, Distance: 7.5431
Step 15: Loss: 0.1502, Entropy: 0.0001, Distance: 7.5057
Step 16: Loss: 0.1489, Entropy: 0.0001, Distance: 7.4387
Step 17: Loss: 0.1470, Entropy: 0.0001, Distance: 7.3459
Step 18: Loss: 0.1447, Entropy: 0.0001, Distance: 7.2309
Step 19: Loss: 0.1421, Entropy: 0.0001, Distance: 7.0970
Step 20: Loss: 0.1391, Entropy: 0.0001, Distance: 6.9469
Step 21: Loss: 0.1358, Entropy: 0.0001, Distance: 6.7833
Step 22: Loss: 0.1323, Entropy: 0.0001, Distance: 6.6086
Step 23: Loss: 0.1287, Entropy: 0.0002, Distance: 6.4252
Step 24: Loss: 0.1249, Entropy: 0.0002, Distance: 6.2352
Step 25: Loss: 0.1210, Entropy: 0.0002, Distance: 6.0406
Step 26: Loss: 0.1171, Entropy: 0.0002, Distance: 5.8434
Step 27: Loss: 0.1132, Entropy: 0.0003, Distance: 5.6454
Step 28: Loss: 0.1093, Entropy: 0.0003, Distance: 5.4484
Step 29: Loss: 0.1054, Entropy: 0.0003, Distance: 5.2542
Step 30: Loss: 0.1017, Entropy: 0.0004, Distance: 5.0643
Step 31: Loss: 0.0981, Entropy: 0.0005, Distance: 4.8805
Step 32: Loss: 0.0946, Entropy: 0.0005, Distance: 4.7040
Step 33: Loss: 0.0914, Entropy: 0.0006, Distance: 4.5363
Step 34: Loss: 0.0883, Entropy: 0.0007, Distance: 4.3782
Step 35: Loss: 0.0855, Entropy: 0.0008, Distance: 4.2307
Step 36: Loss: 0.0829, Entropy: 0.0010, Distance: 4.0942
Step 37: Loss: 0.0805, Entropy: 0.0011, Distance: 3.9690
Step 38: Loss: 0.0784, Entropy: 0.0013, Distance: 3.8549
Step 39: Loss: 0.0764, Entropy: 0.0014, Distance: 3.7516
Step 40: Loss: 0.0747, Entropy: 0.0016, Distance: 3.6587
Step 41: Loss: 0.0732, Entropy: 0.0017, Distance: 3.5753
Step 42: Loss: 0.0718, Entropy: 0.0018, Distance: 3.5007
Step 43: Loss: 0.0706, Entropy: 0.0019, Distance: 3.4339
Step 44: Loss: 0.0695, Entropy: 0.0020, Distance: 3.3741
Step 45: Loss: 0.0685, Entropy: 0.0021, Distance: 3.3203
Step 46: Loss: 0.0676, Entropy: 0.0022, Distance: 3.2715
Step 47: Loss: 0.0667, Entropy: 0.0022, Distance: 3.2270
Step 48: Loss: 0.0659, Entropy: 0.0022, Distance: 3.1857
Step 49: Loss: 0.0651, Entropy: 0.0022, Distance: 3.1471
Step 00: Loss: 1.4139, Entropy: 1.4139, Distance: 0.0000
Step 01: Loss: 0.4509, Entropy: 0.4189, Distance: 1.6000
Step 02: Loss: 0.1085, Entropy: 0.0505, Distance: 2.9015
Step 03: Loss: 0.0872, Entropy: 0.0083, Distance: 3.9463
Step 04: Loss: 0.0968, Entropy: 0.0020, Distance: 4.7413
Step 05: Loss: 0.1076, Entropy: 0.0007, Distance: 5.3454
Step 06: Loss: 0.1163, Entropy: 0.0003, Distance: 5.8026
Step 07: Loss: 0.1230, Entropy: 0.0001, Distance: 6.1442
Step 08: Loss: 0.1279, Entropy: 0.0001, Distance: 6.3924
Step 09: Loss: 0.1313, Entropy: 0.0000, Distance: 6.5642
Step 10: Loss: 0.1335, Entropy: 0.0000, Distance: 6.6724
Step 11: Loss: 0.1346, Entropy: 0.0000, Distance: 6.7273
Step 12: Loss: 0.1348, Entropy: 0.0000, Distance: 6.7373
Step 13: Loss: 0.1342, Entropy: 0.0000, Distance: 6.7096
Step 14: Loss: 0.1330, Entropy: 0.0000, Distance: 6.6504
Step 15: Loss: 0.1313, Entropy: 0.0000, Distance: 6.5649
Step 16: Loss: 0.1292, Entropy: 0.0000, Distance: 6.4577
Step 17: Loss: 0.1267, Entropy: 0.0000, Distance: 6.3327
Step 18: Loss: 0.1239, Entropy: 0.0000, Distance: 6.1933
Step 19: Loss: 0.1209, Entropy: 0.0000, Distance: 6.0426
Step 20: Loss: 0.1177, Entropy: 0.0000, Distance: 5.8833
Step 21: Loss: 0.1144, Entropy: 0.0000, Distance: 5.7178
Step 22: Loss: 0.1110, Entropy: 0.0000, Distance: 5.5483
Step 23: Loss: 0.1076, Entropy: 0.0000, Distance: 5.3769
Step 24: Loss: 0.1041, Entropy: 0.0000, Distance: 5.2054
Step 25: Loss: 0.1007, Entropy: 0.0000, Distance: 5.0356
Step 26: Loss: 0.0974, Entropy: 0.0000, Distance: 4.8692
Step 27: Loss: 0.0942, Entropy: 0.0000, Distance: 4.7080
Step 28: Loss: 0.0911, Entropy: 0.0000, Distance: 4.5534
Step 29: Loss: 0.0882, Entropy: 0.0000, Distance: 4.4066
Step 30: Loss: 0.0854, Entropy: 0.0000, Distance: 4.2687
Step 31: Loss: 0.0828, Entropy: 0.0000, Distance: 4.1403
Step 32: Loss: 0.0805, Entropy: 0.0000, Distance: 4.0218
Step 33: Loss: 0.0783, Entropy: 0.0000, Distance: 3.9132
Step 34: Loss: 0.0763, Entropy: 0.0000, Distance: 3.8143
Step 35: Loss: 0.0746, Entropy: 0.0001, Distance: 3.7248
Step 36: Loss: 0.0729, Entropy: 0.0001, Distance: 3.6440
Step 37: Loss: 0.0715, Entropy: 0.0001, Distance: 3.5711
Step 38: Loss: 0.0702, Entropy: 0.0001, Distance: 3.5054
Step 39: Loss: 0.0690, Entropy: 0.0001, Distance: 3.4457
Step 40: Loss: 0.0679, Entropy: 0.0001, Distance: 3.3911
Step 41: Loss: 0.0669, Entropy: 0.0001, Distance: 3.3405
Step 42: Loss: 0.0660, Entropy: 0.0001, Distance: 3.2931
Step 43: Loss: 0.0651, Entropy: 0.0002, Distance: 3.2479
Step 44: Loss: 0.0643, Entropy: 0.0002, Distance: 3.2042
Step 45: Loss: 0.0634, Entropy: 0.0002, Distance: 3.1613
Step 46: Loss: 0.0626, Entropy: 0.0002, Distance: 3.1188
Step 47: Loss: 0.0618, Entropy: 0.0002, Distance: 3.0762
Step 48: Loss: 0.0609, Entropy: 0.0003, Distance: 3.0331
Step 49: Loss: 0.0601, Entropy: 0.0003, Distance: 2.9895
Step 00: Loss: 1.1075, Entropy: 1.1075, Distance: 0.0000
Step 01: Loss: 0.1812, Entropy: 0.1492, Distance: 1.6000
Step 02: Loss: 0.0738, Entropy: 0.0188, Distance: 2.7508
Step 03: Loss: 0.0753, Entropy: 0.0037, Distance: 3.5822
Step 04: Loss: 0.0848, Entropy: 0.0010, Distance: 4.1915
Step 05: Loss: 0.0932, Entropy: 0.0004, Distance: 4.6422
Step 06: Loss: 0.0996, Entropy: 0.0002, Distance: 4.9743
Step 07: Loss: 0.1044, Entropy: 0.0001, Distance: 5.2144
Step 08: Loss: 0.1077, Entropy: 0.0000, Distance: 5.3816
Step 09: Loss: 0.1098, Entropy: 0.0000, Distance: 5.4901
Step 10: Loss: 0.1110, Entropy: 0.0000, Distance: 5.5509
Step 11: Loss: 0.1115, Entropy: 0.0000, Distance: 5.5727
Step 12: Loss: 0.1113, Entropy: 0.0000, Distance: 5.5626
Step 13: Loss: 0.1105, Entropy: 0.0000, Distance: 5.5261
Step 14: Loss: 0.1094, Entropy: 0.0000, Distance: 5.4681
Step 15: Loss: 0.1079, Entropy: 0.0000, Distance: 5.3923
Step 16: Loss: 0.1060, Entropy: 0.0000, Distance: 5.3017
Step 17: Loss: 0.1040, Entropy: 0.0000, Distance: 5.1989
Step 18: Loss: 0.1017, Entropy: 0.0000, Distance: 5.0859
Step 19: Loss: 0.0993, Entropy: 0.0000, Distance: 4.9648
Step 20: Loss: 0.0967, Entropy: 0.0000, Distance: 4.8372
Step 21: Loss: 0.0941, Entropy: 0.0000, Distance: 4.7048
Step 22: Loss: 0.0914, Entropy: 0.0000, Distance: 4.5694
Step 23: Loss: 0.0887, Entropy: 0.0000, Distance: 4.4325
Step 24: Loss: 0.0859, Entropy: 0.0000, Distance: 4.2959
Step 25: Loss: 0.0832, Entropy: 0.0000, Distance: 4.1609
Step 26: Loss: 0.0806, Entropy: 0.0000, Distance: 4.0288
Step 27: Loss: 0.0780, Entropy: 0.0000, Distance: 3.9007
Step 28: Loss: 0.0756, Entropy: 0.0000, Distance: 3.7774
Step 29: Loss: 0.0732, Entropy: 0.0000, Distance: 3.6595
Step 30: Loss: 0.0710, Entropy: 0.0000, Distance: 3.5474
Step 31: Loss: 0.0688, Entropy: 0.0000, Distance: 3.4415
Step 32: Loss: 0.0669, Entropy: 0.0000, Distance: 3.3422
Step 33: Loss: 0.0650, Entropy: 0.0000, Distance: 3.2495
Step 34: Loss: 0.0633, Entropy: 0.0000, Distance: 3.1634
Step 35: Loss: 0.0617, Entropy: 0.0000, Distance: 3.0839
Step 36: Loss: 0.0602, Entropy: 0.0000, Distance: 3.0107
Step 37: Loss: 0.0589, Entropy: 0.0000, Distance: 2.9434
Step 38: Loss: 0.0577, Entropy: 0.0000, Distance: 2.8817
Step 39: Loss: 0.0565, Entropy: 0.0000, Distance: 2.8254
Step 40: Loss: 0.0555, Entropy: 0.0000, Distance: 2.7740
Step 41: Loss: 0.0546, Entropy: 0.0000, Distance: 2.7271
Step 42: Loss: 0.0537, Entropy: 0.0000, Distance: 2.6842
Step 43: Loss: 0.0529, Entropy: 0.0000, Distance: 2.6448
Step 44: Loss: 0.0522, Entropy: 0.0000, Distance: 2.6082
Step 45: Loss: 0.0515, Entropy: 0.0001, Distance: 2.5739
Step 46: Loss: 0.0509, Entropy: 0.0001, Distance: 2.5414
Step 47: Loss: 0.0503, Entropy: 0.0001, Distance: 2.5099
Step 48: Loss: 0.0496, Entropy: 0.0001, Distance: 2.4789
Step 49: Loss: 0.0490, Entropy: 0.0001, Distance: 2.4480
Step 00: Loss: 0.7103, Entropy: 0.7103, Distance: 0.0000
Step 01: Loss: 0.1578, Entropy: 0.1258, Distance: 1.6000
Step 02: Loss: 0.0809, Entropy: 0.0260, Distance: 2.7473
Step 03: Loss: 0.0794, Entropy: 0.0074, Distance: 3.5963
Step 04: Loss: 0.0874, Entropy: 0.0028, Distance: 4.2271
Step 05: Loss: 0.0952, Entropy: 0.0013, Distance: 4.6959
Step 06: Loss: 0.1015, Entropy: 0.0007, Distance: 5.0394
Step 07: Loss: 0.1061, Entropy: 0.0005, Distance: 5.2838
Step 08: Loss: 0.1093, Entropy: 0.0003, Distance: 5.4482
Step 09: Loss: 0.1112, Entropy: 0.0003, Distance: 5.5473
Step 10: Loss: 0.1121, Entropy: 0.0002, Distance: 5.5930
Step 11: Loss: 0.1121, Entropy: 0.0002, Distance: 5.5944
Step 12: Loss: 0.1114, Entropy: 0.0002, Distance: 5.5594
Step 13: Loss: 0.1101, Entropy: 0.0002, Distance: 5.4947
Step 14: Loss: 0.1083, Entropy: 0.0002, Distance: 5.4057
Step 15: Loss: 0.1061, Entropy: 0.0002, Distance: 5.2974
Step 16: Loss: 0.1037, Entropy: 0.0002, Distance: 5.1739
Step 17: Loss: 0.1010, Entropy: 0.0002, Distance: 5.0386
Step 18: Loss: 0.0981, Entropy: 0.0002, Distance: 4.8947
Step 19: Loss: 0.0951, Entropy: 0.0002, Distance: 4.7449
Step 20: Loss: 0.0921, Entropy: 0.0003, Distance: 4.5918
Step 21: Loss: 0.0891, Entropy: 0.0003, Distance: 4.4375
Step 22: Loss: 0.0860, Entropy: 0.0003, Distance: 4.2840
Step 23: Loss: 0.0831, Entropy: 0.0004, Distance: 4.1330
Step 24: Loss: 0.0802, Entropy: 0.0005, Distance: 3.9859
Step 25: Loss: 0.0774, Entropy: 0.0005, Distance: 3.8441
Step 26: Loss: 0.0748, Entropy: 0.0006, Distance: 3.7088
Step 27: Loss: 0.0723, Entropy: 0.0007, Distance: 3.5809
Step 28: Loss: 0.0700, Entropy: 0.0008, Distance: 3.4610
Step 29: Loss: 0.0679, Entropy: 0.0009, Distance: 3.3491
Step 30: Loss: 0.0659, Entropy: 0.0010, Distance: 3.2455
Step 31: Loss: 0.0642, Entropy: 0.0012, Distance: 3.1499
Step 32: Loss: 0.0625, Entropy: 0.0013, Distance: 3.0622
Step 33: Loss: 0.0610, Entropy: 0.0014, Distance: 2.9821
Step 34: Loss: 0.0597, Entropy: 0.0015, Distance: 2.9092
Step 35: Loss: 0.0585, Entropy: 0.0016, Distance: 2.8428
Step 36: Loss: 0.0574, Entropy: 0.0017, Distance: 2.7819
Step 37: Loss: 0.0563, Entropy: 0.0018, Distance: 2.7254
Step 38: Loss: 0.0553, Entropy: 0.0018, Distance: 2.6726
Step 39: Loss: 0.0543, Entropy: 0.0019, Distance: 2.6227
Step 40: Loss: 0.0534, Entropy: 0.0019, Distance: 2.5753
Step 41: Loss: 0.0526, Entropy: 0.0020, Distance: 2.5303
Step 42: Loss: 0.0517, Entropy: 0.0020, Distance: 2.4872
Step 43: Loss: 0.0509, Entropy: 0.0020, Distance: 2.4457
Step 44: Loss: 0.0501, Entropy: 0.0020, Distance: 2.4053
Step 45: Loss: 0.0493, Entropy: 0.0020, Distance: 2.3654
Step 46: Loss: 0.0485, Entropy: 0.0020, Distance: 2.3259
Step 47: Loss: 0.0478, Entropy: 0.0020, Distance: 2.2865
Step 48: Loss: 0.0470, Entropy: 0.0021, Distance: 2.2471
Step 49: Loss: 0.0462, Entropy: 0.0021, Distance: 2.2077
Step 00: Loss: 1.6198, Entropy: 1.6198, Distance: 0.0000
Step 01: Loss: 0.8068, Entropy: 0.7748, Distance: 1.6000
Step 02: Loss: 0.2098, Entropy: 0.1550, Distance: 2.7404
Step 03: Loss: 0.0961, Entropy: 0.0200, Distance: 3.8069
Step 04: Loss: 0.0970, Entropy: 0.0032, Distance: 4.6888
Step 05: Loss: 0.1087, Entropy: 0.0007, Distance: 5.3996
Step 06: Loss: 0.1196, Entropy: 0.0002, Distance: 5.9702
Step 07: Loss: 0.1286, Entropy: 0.0001, Distance: 6.4264
Step 08: Loss: 0.1358, Entropy: 0.0000, Distance: 6.7880
Step 09: Loss: 0.1414, Entropy: 0.0000, Distance: 7.0700
Step 10: Loss: 0.1457, Entropy: 0.0000, Distance: 7.2846
Step 11: Loss: 0.1488, Entropy: 0.0000, Distance: 7.4415
Step 12: Loss: 0.1510, Entropy: 0.0000, Distance: 7.5485
Step 13: Loss: 0.1522, Entropy: 0.0000, Distance: 7.6124
Step 14: Loss: 0.1528, Entropy: 0.0000, Distance: 7.6389
Step 15: Loss: 0.1527, Entropy: 0.0000, Distance: 7.6329
Step 16: Loss: 0.1520, Entropy: 0.0000, Distance: 7.5985
Step 17: Loss: 0.1508, Entropy: 0.0000, Distance: 7.5395
Step 18: Loss: 0.1492, Entropy: 0.0000, Distance: 7.4593
Step 19: Loss: 0.1472, Entropy: 0.0000, Distance: 7.3607
Step 20: Loss: 0.1449, Entropy: 0.0000, Distance: 7.2463
Step 21: Loss: 0.1424, Entropy: 0.0000, Distance: 7.1185
Step 22: Loss: 0.1396, Entropy: 0.0000, Distance: 6.9794
Step 23: Loss: 0.1366, Entropy: 0.0000, Distance: 6.8309
Step 24: Loss: 0.1335, Entropy: 0.0000, Distance: 6.6748
Step 25: Loss: 0.1303, Entropy: 0.0000, Distance: 6.5128
Step 26: Loss: 0.1269, Entropy: 0.0000, Distance: 6.3463
Step 27: Loss: 0.1235, Entropy: 0.0000, Distance: 6.1768
Step 28: Loss: 0.1201, Entropy: 0.0000, Distance: 6.0056
Step 29: Loss: 0.1167, Entropy: 0.0000, Distance: 5.8341
Step 30: Loss: 0.1133, Entropy: 0.0000, Distance: 5.6633
Step 31: Loss: 0.1099, Entropy: 0.0000, Distance: 5.4944
Step 32: Loss: 0.1066, Entropy: 0.0000, Distance: 5.3283
Step 33: Loss: 0.1033, Entropy: 0.0000, Distance: 5.1661
Step 34: Loss: 0.1002, Entropy: 0.0000, Distance: 5.0083
Step 35: Loss: 0.0971, Entropy: 0.0000, Distance: 4.8559
Step 36: Loss: 0.0942, Entropy: 0.0000, Distance: 4.7092
Step 37: Loss: 0.0914, Entropy: 0.0000, Distance: 4.5689
Step 38: Loss: 0.0887, Entropy: 0.0000, Distance: 4.4354
Step 39: Loss: 0.0862, Entropy: 0.0000, Distance: 4.3089
Step 40: Loss: 0.0838, Entropy: 0.0000, Distance: 4.1895
Step 41: Loss: 0.0816, Entropy: 0.0000, Distance: 4.0774
Step 42: Loss: 0.0795, Entropy: 0.0000, Distance: 3.9724
Step 43: Loss: 0.0775, Entropy: 0.0000, Distance: 3.8744
Step 44: Loss: 0.0757, Entropy: 0.0000, Distance: 3.7831
Step 45: Loss: 0.0740, Entropy: 0.0000, Distance: 3.6983
Step 46: Loss: 0.0724, Entropy: 0.0000, Distance: 3.6197
Step 47: Loss: 0.0710, Entropy: 0.0000, Distance: 3.5468
Step 48: Loss: 0.0696, Entropy: 0.0000, Distance: 3.4793
Step 49: Loss: 0.0684, Entropy: 0.0000, Distance: 3.4166
Step 00: Loss: 1.4204, Entropy: 1.4204, Distance: 0.0000
Step 01: Loss: 0.9341, Entropy: 0.9021, Distance: 1.6000
Step 02: Loss: 0.2978, Entropy: 0.2471, Distance: 2.5380
Step 03: Loss: 0.1057, Entropy: 0.0347, Distance: 3.5504
Step 04: Loss: 0.0943, Entropy: 0.0056, Distance: 4.4355
Step 05: Loss: 0.1043, Entropy: 0.0013, Distance: 5.1533
Step 06: Loss: 0.1149, Entropy: 0.0004, Distance: 5.7240
Step 07: Loss: 0.1236, Entropy: 0.0002, Distance: 6.1716
Step 08: Loss: 0.1305, Entropy: 0.0001, Distance: 6.5162
Step 09: Loss: 0.1356, Entropy: 0.0001, Distance: 6.7738
Step 10: Loss: 0.1392, Entropy: 0.0001, Distance: 6.9573
Step 11: Loss: 0.1416, Entropy: 0.0001, Distance: 7.0773
Step 12: Loss: 0.1429, Entropy: 0.0001, Distance: 7.1428
Step 13: Loss: 0.1433, Entropy: 0.0001, Distance: 7.1615
Step 14: Loss: 0.1429, Entropy: 0.0001, Distance: 7.1402
Step 15: Loss: 0.1418, Entropy: 0.0001, Distance: 7.0845
Step 16: Loss: 0.1401, Entropy: 0.0001, Distance: 7.0000
Step 17: Loss: 0.1379, Entropy: 0.0001, Distance: 6.8911
Step 18: Loss: 0.1354, Entropy: 0.0001, Distance: 6.7623
Step 19: Loss: 0.1325, Entropy: 0.0001, Distance: 6.6172
Step 20: Loss: 0.1293, Entropy: 0.0001, Distance: 6.4594
Step 21: Loss: 0.1260, Entropy: 0.0002, Distance: 6.2921
Step 22: Loss: 0.1225, Entropy: 0.0002, Distance: 6.1180
Step 23: Loss: 0.1190, Entropy: 0.0002, Distance: 5.9399
Step 24: Loss: 0.1154, Entropy: 0.0002, Distance: 5.7601
Step 25: Loss: 0.1119, Entropy: 0.0003, Distance: 5.5808
Step 26: Loss: 0.1084, Entropy: 0.0003, Distance: 5.4041
Step 27: Loss: 0.1050, Entropy: 0.0003, Distance: 5.2319
Step 28: Loss: 0.1017, Entropy: 0.0004, Distance: 5.0656
Step 29: Loss: 0.0986, Entropy: 0.0004, Distance: 4.9067
Step 30: Loss: 0.0956, Entropy: 0.0005, Distance: 4.7562
Step 31: Loss: 0.0928, Entropy: 0.0005, Distance: 4.6150
Step 32: Loss: 0.0902, Entropy: 0.0006, Distance: 4.4834
Step 33: Loss: 0.0879, Entropy: 0.0006, Distance: 4.3616
Step 34: Loss: 0.0857, Entropy: 0.0007, Distance: 4.2495
Step 35: Loss: 0.0837, Entropy: 0.0007, Distance: 4.1468
Step 36: Loss: 0.0818, Entropy: 0.0008, Distance: 4.0529
Step 37: Loss: 0.0802, Entropy: 0.0008, Distance: 3.9671
Step 38: Loss: 0.0786, Entropy: 0.0009, Distance: 3.8886
Step 39: Loss: 0.0772, Entropy: 0.0009, Distance: 3.8166
Step 40: Loss: 0.0759, Entropy: 0.0009, Distance: 3.7501
Step 41: Loss: 0.0747, Entropy: 0.0009, Distance: 3.6881
Step 42: Loss: 0.0735, Entropy: 0.0009, Distance: 3.6300
Step 43: Loss: 0.0724, Entropy: 0.0009, Distance: 3.5750
Step 44: Loss: 0.0713, Entropy: 0.0009, Distance: 3.5224
Step 45: Loss: 0.0703, Entropy: 0.0008, Distance: 3.4719
Step 46: Loss: 0.0693, Entropy: 0.0008, Distance: 3.4230
Step 47: Loss: 0.0683, Entropy: 0.0008, Distance: 3.3754
Step 48: Loss: 0.0673, Entropy: 0.0007, Distance: 3.3287
Step 49: Loss: 0.0663, Entropy: 0.0007, Distance: 3.2826
Step 00: Loss: 1.5214, Entropy: 1.5214, Distance: 0.0000
Step 01: Loss: 0.4737, Entropy: 0.4417, Distance: 1.6000
Step 02: Loss: 0.1410, Entropy: 0.0809, Distance: 3.0062
Step 03: Loss: 0.1023, Entropy: 0.0195, Distance: 4.1391
Step 04: Loss: 0.1066, Entropy: 0.0062, Distance: 5.0210
Step 05: Loss: 0.1166, Entropy: 0.0024, Distance: 5.7075
Step 06: Loss: 0.1260, Entropy: 0.0011, Distance: 6.2425
Step 07: Loss: 0.1338, Entropy: 0.0006, Distance: 6.6577
Step 08: Loss: 0.1399, Entropy: 0.0003, Distance: 6.9758
Step 09: Loss: 0.1445, Entropy: 0.0002, Distance: 7.2140
Step 10: Loss: 0.1479, Entropy: 0.0002, Distance: 7.3854
Step 11: Loss: 0.1501, Entropy: 0.0001, Distance: 7.5003
Step 12: Loss: 0.1514, Entropy: 0.0001, Distance: 7.5670
Step 13: Loss: 0.1519, Entropy: 0.0001, Distance: 7.5923
Step 14: Loss: 0.1517, Entropy: 0.0001, Distance: 7.5816
Step 15: Loss: 0.1508, Entropy: 0.0001, Distance: 7.5396
Step 16: Loss: 0.1495, Entropy: 0.0000, Distance: 7.4703
Step 17: Loss: 0.1476, Entropy: 0.0000, Distance: 7.3772
Step 18: Loss: 0.1453, Entropy: 0.0000, Distance: 7.2635
Step 19: Loss: 0.1427, Entropy: 0.0000, Distance: 7.1321
Step 20: Loss: 0.1398, Entropy: 0.0000, Distance: 6.9857
Step 21: Loss: 0.1366, Entropy: 0.0000, Distance: 6.8268
Step 22: Loss: 0.1332, Entropy: 0.0000, Distance: 6.6579
Step 23: Loss: 0.1297, Entropy: 0.0001, Distance: 6.4812
Step 24: Loss: 0.1260, Entropy: 0.0001, Distance: 6.2985
Step 25: Loss: 0.1223, Entropy: 0.0001, Distance: 6.1119
Step 26: Loss: 0.1185, Entropy: 0.0001, Distance: 5.9229
Step 27: Loss: 0.1147, Entropy: 0.0001, Distance: 5.7330
Step 28: Loss: 0.1110, Entropy: 0.0001, Distance: 5.5436
Step 29: Loss: 0.1072, Entropy: 0.0001, Distance: 5.3558
Step 30: Loss: 0.1035, Entropy: 0.0001, Distance: 5.1708
Step 31: Loss: 0.0999, Entropy: 0.0001, Distance: 4.9898
Step 32: Loss: 0.0964, Entropy: 0.0002, Distance: 4.8137
Step 33: Loss: 0.0931, Entropy: 0.0002, Distance: 4.6434
Step 34: Loss: 0.0898, Entropy: 0.0002, Distance: 4.4800
Step 35: Loss: 0.0867, Entropy: 0.0003, Distance: 4.3240
Step 36: Loss: 0.0838, Entropy: 0.0003, Distance: 4.1762
Step 37: Loss: 0.0811, Entropy: 0.0004, Distance: 4.0370
Step 38: Loss: 0.0786, Entropy: 0.0004, Distance: 3.9069
Step 39: Loss: 0.0762, Entropy: 0.0005, Distance: 3.7860
Step 40: Loss: 0.0741, Entropy: 0.0006, Distance: 3.6745
Step 41: Loss: 0.0722, Entropy: 0.0007, Distance: 3.5722
Step 42: Loss: 0.0704, Entropy: 0.0008, Distance: 3.4789
Step 43: Loss: 0.0689, Entropy: 0.0010, Distance: 3.3942
Step 44: Loss: 0.0675, Entropy: 0.0011, Distance: 3.3177
Step 45: Loss: 0.0662, Entropy: 0.0012, Distance: 3.2485
Step 46: Loss: 0.0651, Entropy: 0.0014, Distance: 3.1860
Step 47: Loss: 0.0641, Entropy: 0.0015, Distance: 3.1291
Step 48: Loss: 0.0631, Entropy: 0.0016, Distance: 3.0770
Step 49: Loss: 0.0623, Entropy: 0.0017, Distance: 3.0289
Step 00: Loss: 1.0511, Entropy: 1.0511, Distance: 0.0000
Step 01: Loss: 0.2774, Entropy: 0.2454, Distance: 1.6000
Step 02: Loss: 0.0866, Entropy: 0.0275, Distance: 2.9536
Step 03: Loss: 0.0835, Entropy: 0.0046, Distance: 3.9430
Step 04: Loss: 0.0943, Entropy: 0.0012, Distance: 4.6541
Step 05: Loss: 0.1037, Entropy: 0.0004, Distance: 5.1658
Step 06: Loss: 0.1108, Entropy: 0.0002, Distance: 5.5286
Step 07: Loss: 0.1156, Entropy: 0.0001, Distance: 5.7757
Step 08: Loss: 0.1187, Entropy: 0.0001, Distance: 5.9309
Step 09: Loss: 0.1203, Entropy: 0.0000, Distance: 6.0121
Step 10: Loss: 0.1207, Entropy: 0.0000, Distance: 6.0333
Step 11: Loss: 0.1201, Entropy: 0.0000, Distance: 6.0060
Step 12: Loss: 0.1188, Entropy: 0.0000, Distance: 5.9399
Step 13: Loss: 0.1169, Entropy: 0.0000, Distance: 5.8428
Step 14: Loss: 0.1145, Entropy: 0.0000, Distance: 5.7218
Step 15: Loss: 0.1117, Entropy: 0.0000, Distance: 5.5826
Step 16: Loss: 0.1086, Entropy: 0.0000, Distance: 5.4302
Step 17: Loss: 0.1054, Entropy: 0.0000, Distance: 5.2688
Step 18: Loss: 0.1021, Entropy: 0.0000, Distance: 5.1023
Step 19: Loss: 0.0987, Entropy: 0.0000, Distance: 4.9340
Step 20: Loss: 0.0954, Entropy: 0.0000, Distance: 4.7667
Step 21: Loss: 0.0921, Entropy: 0.0000, Distance: 4.6031
Step 22: Loss: 0.0889, Entropy: 0.0000, Distance: 4.4451
Step 23: Loss: 0.0859, Entropy: 0.0000, Distance: 4.2941
Step 24: Loss: 0.0830, Entropy: 0.0000, Distance: 4.1511
Step 25: Loss: 0.0804, Entropy: 0.0000, Distance: 4.0167
Step 26: Loss: 0.0779, Entropy: 0.0000, Distance: 3.8911
Step 27: Loss: 0.0755, Entropy: 0.0000, Distance: 3.7748
Step 28: Loss: 0.0734, Entropy: 0.0000, Distance: 3.6681
Step 29: Loss: 0.0715, Entropy: 0.0000, Distance: 3.5713
Step 30: Loss: 0.0697, Entropy: 0.0000, Distance: 3.4845
Step 31: Loss: 0.0682, Entropy: 0.0001, Distance: 3.4073
Step 32: Loss: 0.0668, Entropy: 0.0001, Distance: 3.3391
Step 33: Loss: 0.0656, Entropy: 0.0001, Distance: 3.2786
Step 34: Loss: 0.0646, Entropy: 0.0001, Distance: 3.2242
Step 35: Loss: 0.0636, Entropy: 0.0001, Distance: 3.1744
Step 36: Loss: 0.0626, Entropy: 0.0001, Distance: 3.1276
Step 37: Loss: 0.0617, Entropy: 0.0001, Distance: 3.0821
Step 38: Loss: 0.0608, Entropy: 0.0001, Distance: 3.0367
Step 39: Loss: 0.0599, Entropy: 0.0001, Distance: 2.9905
Step 40: Loss: 0.0590, Entropy: 0.0001, Distance: 2.9430
Step 41: Loss: 0.0580, Entropy: 0.0001, Distance: 2.8943
Step 42: Loss: 0.0570, Entropy: 0.0001, Distance: 2.8444
Step 43: Loss: 0.0560, Entropy: 0.0002, Distance: 2.7935
Step 44: Loss: 0.0550, Entropy: 0.0002, Distance: 2.7418
Step 45: Loss: 0.0540, Entropy: 0.0002, Distance: 2.6893
Step 46: Loss: 0.0529, Entropy: 0.0002, Distance: 2.6364
Step 47: Loss: 0.0519, Entropy: 0.0002, Distance: 2.5834
Step 48: Loss: 0.0509, Entropy: 0.0002, Distance: 2.5305
Step 49: Loss: 0.0498, Entropy: 0.0003, Distance: 2.4782
Step 00: Loss: 1.0693, Entropy: 1.0693, Distance: 0.0000
Step 01: Loss: 0.2379, Entropy: 0.2059, Distance: 1.6000
Step 02: Loss: 0.0797, Entropy: 0.0222, Distance: 2.8716
Step 03: Loss: 0.0802, Entropy: 0.0038, Distance: 3.8196
Step 04: Loss: 0.0915, Entropy: 0.0010, Distance: 4.5247
Step 05: Loss: 0.1015, Entropy: 0.0004, Distance: 5.0532
Step 06: Loss: 0.1091, Entropy: 0.0002, Distance: 5.4478
Step 07: Loss: 0.1148, Entropy: 0.0001, Distance: 5.7371
Step 08: Loss: 0.1189, Entropy: 0.0001, Distance: 5.9417
Step 09: Loss: 0.1216, Entropy: 0.0000, Distance: 6.0768
Step 10: Loss: 0.1231, Entropy: 0.0000, Distance: 6.1542
Step 11: Loss: 0.1237, Entropy: 0.0000, Distance: 6.1835
Step 12: Loss: 0.1235, Entropy: 0.0000, Distance: 6.1722
Step 13: Loss: 0.1226, Entropy: 0.0000, Distance: 6.1268
Step 14: Loss: 0.1211, Entropy: 0.0000, Distance: 6.0529
Step 15: Loss: 0.1191, Entropy: 0.0000, Distance: 5.9552
Step 16: Loss: 0.1168, Entropy: 0.0000, Distance: 5.8381
Step 17: Loss: 0.1141, Entropy: 0.0000, Distance: 5.7054
Step 18: Loss: 0.1112, Entropy: 0.0000, Distance: 5.5606
Step 19: Loss: 0.1082, Entropy: 0.0000, Distance: 5.4070
Step 20: Loss: 0.1050, Entropy: 0.0000, Distance: 5.2474
Step 21: Loss: 0.1017, Entropy: 0.0000, Distance: 5.0843
Step 22: Loss: 0.0984, Entropy: 0.0000, Distance: 4.9201
Step 23: Loss: 0.0952, Entropy: 0.0001, Distance: 4.7567
Step 24: Loss: 0.0920, Entropy: 0.0001, Distance: 4.5959
Step 25: Loss: 0.0889, Entropy: 0.0001, Distance: 4.4392
Step 26: Loss: 0.0858, Entropy: 0.0001, Distance: 4.2878
Step 27: Loss: 0.0830, Entropy: 0.0001, Distance: 4.1428
Step 28: Loss: 0.0802, Entropy: 0.0001, Distance: 4.0048
Step 29: Loss: 0.0776, Entropy: 0.0001, Distance: 3.8746
Step 30: Loss: 0.0752, Entropy: 0.0002, Distance: 3.7523
Step 31: Loss: 0.0730, Entropy: 0.0002, Distance: 3.6380
Step 32: Loss: 0.0709, Entropy: 0.0002, Distance: 3.5316
Step 33: Loss: 0.0690, Entropy: 0.0003, Distance: 3.4331
Step 34: Loss: 0.0672, Entropy: 0.0003, Distance: 3.3421
Step 35: Loss: 0.0656, Entropy: 0.0004, Distance: 3.2585
Step 36: Loss: 0.0641, Entropy: 0.0005, Distance: 3.1819
Step 37: Loss: 0.0628, Entropy: 0.0005, Distance: 3.1115
Step 38: Loss: 0.0615, Entropy: 0.0006, Distance: 3.0467
Step 39: Loss: 0.0604, Entropy: 0.0007, Distance: 2.9866
Step 40: Loss: 0.0593, Entropy: 0.0007, Distance: 2.9303
Step 41: Loss: 0.0583, Entropy: 0.0008, Distance: 2.8773
Step 42: Loss: 0.0574, Entropy: 0.0009, Distance: 2.8268
Step 43: Loss: 0.0565, Entropy: 0.0009, Distance: 2.7783
Step 44: Loss: 0.0556, Entropy: 0.0009, Distance: 2.7311
Step 45: Loss: 0.0547, Entropy: 0.0010, Distance: 2.6849
Step 46: Loss: 0.0538, Entropy: 0.0010, Distance: 2.6392
Step 47: Loss: 0.0529, Entropy: 0.0010, Distance: 2.5938
Step 48: Loss: 0.0520, Entropy: 0.0011, Distance: 2.5486
Step 49: Loss: 0.0511, Entropy: 0.0011, Distance: 2.5034
Step 00: Loss: 0.4985, Entropy: 0.4985, Distance: 0.0000
Step 01: Loss: 0.0753, Entropy: 0.0433, Distance: 1.6000
Step 02: Loss: 0.0584, Entropy: 0.0062, Distance: 2.6090
Step 03: Loss: 0.0673, Entropy: 0.0015, Distance: 3.2890
Step 04: Loss: 0.0757, Entropy: 0.0005, Distance: 3.7582
Step 05: Loss: 0.0818, Entropy: 0.0002, Distance: 4.0807
Step 06: Loss: 0.0860, Entropy: 0.0001, Distance: 4.2951
Step 07: Loss: 0.0886, Entropy: 0.0001, Distance: 4.4273
Step 08: Loss: 0.0900, Entropy: 0.0000, Distance: 4.4955
Step 09: Loss: 0.0903, Entropy: 0.0000, Distance: 4.5131
Step 10: Loss: 0.0898, Entropy: 0.0000, Distance: 4.4906
Step 11: Loss: 0.0888, Entropy: 0.0000, Distance: 4.4364
Step 12: Loss: 0.0872, Entropy: 0.0000, Distance: 4.3575
Step 13: Loss: 0.0852, Entropy: 0.0000, Distance: 4.2597
Step 14: Loss: 0.0830, Entropy: 0.0000, Distance: 4.1481
Step 15: Loss: 0.0806, Entropy: 0.0000, Distance: 4.0269
Step 16: Loss: 0.0780, Entropy: 0.0000, Distance: 3.9000
Step 17: Loss: 0.0754, Entropy: 0.0000, Distance: 3.7702
Step 18: Loss: 0.0728, Entropy: 0.0000, Distance: 3.6402
Step 19: Loss: 0.0703, Entropy: 0.0000, Distance: 3.5122
Step 20: Loss: 0.0678, Entropy: 0.0000, Distance: 3.3879
Step 21: Loss: 0.0654, Entropy: 0.0001, Distance: 3.2689
Step 22: Loss: 0.0632, Entropy: 0.0001, Distance: 3.1562
Step 23: Loss: 0.0611, Entropy: 0.0001, Distance: 3.0505
Step 24: Loss: 0.0591, Entropy: 0.0001, Distance: 2.9519
Step 25: Loss: 0.0573, Entropy: 0.0001, Distance: 2.8605
Step 26: Loss: 0.0557, Entropy: 0.0001, Distance: 2.7762
Step 27: Loss: 0.0541, Entropy: 0.0002, Distance: 2.6991
Step 28: Loss: 0.0528, Entropy: 0.0002, Distance: 2.6290
Step 29: Loss: 0.0516, Entropy: 0.0002, Distance: 2.5660
Step 30: Loss: 0.0505, Entropy: 0.0003, Distance: 2.5094
Step 31: Loss: 0.0495, Entropy: 0.0003, Distance: 2.4585
Step 32: Loss: 0.0486, Entropy: 0.0004, Distance: 2.4123
Step 33: Loss: 0.0478, Entropy: 0.0004, Distance: 2.3697
Step 34: Loss: 0.0471, Entropy: 0.0005, Distance: 2.3295
Step 35: Loss: 0.0463, Entropy: 0.0005, Distance: 2.2907
Step 36: Loss: 0.0456, Entropy: 0.0006, Distance: 2.2526
Step 37: Loss: 0.0449, Entropy: 0.0007, Distance: 2.2147
Step 38: Loss: 0.0442, Entropy: 0.0007, Distance: 2.1768
Step 39: Loss: 0.0435, Entropy: 0.0008, Distance: 2.1389
Step 40: Loss: 0.0428, Entropy: 0.0008, Distance: 2.1009
Step 41: Loss: 0.0421, Entropy: 0.0009, Distance: 2.0630
Step 42: Loss: 0.0414, Entropy: 0.0009, Distance: 2.0249
Step 43: Loss: 0.0407, Entropy: 0.0010, Distance: 1.9867
Step 44: Loss: 0.0400, Entropy: 0.0010, Distance: 1.9483
Step 45: Loss: 0.0392, Entropy: 0.0010, Distance: 1.9100
Step 46: Loss: 0.0385, Entropy: 0.0011, Distance: 1.8720
Step 47: Loss: 0.0378, Entropy: 0.0011, Distance: 1.8345
Step 48: Loss: 0.0371, Entropy: 0.0011, Distance: 1.7976
Step 49: Loss: 0.0364, Entropy: 0.0011, Distance: 1.7611
Step 00: Loss: 1.0583, Entropy: 1.0583, Distance: 0.0000
Step 01: Loss: 0.5495, Entropy: 0.5175, Distance: 1.6000
Step 02: Loss: 0.1605, Entropy: 0.1058, Distance: 2.7359
Step 03: Loss: 0.0931, Entropy: 0.0176, Distance: 3.7730
Step 04: Loss: 0.0960, Entropy: 0.0039, Distance: 4.6043
Step 05: Loss: 0.1063, Entropy: 0.0012, Distance: 5.2548
Step 06: Loss: 0.1157, Entropy: 0.0005, Distance: 5.7600
Step 07: Loss: 0.1232, Entropy: 0.0002, Distance: 6.1478
Step 08: Loss: 0.1289, Entropy: 0.0001, Distance: 6.4394
Step 09: Loss: 0.1331, Entropy: 0.0001, Distance: 6.6507
Step 10: Loss: 0.1359, Entropy: 0.0001, Distance: 6.7947
Step 11: Loss: 0.1377, Entropy: 0.0000, Distance: 6.8814
Step 12: Loss: 0.1384, Entropy: 0.0000, Distance: 6.9193
Step 13: Loss: 0.1383, Entropy: 0.0000, Distance: 6.9156
Step 14: Loss: 0.1375, Entropy: 0.0000, Distance: 6.8762
Step 15: Loss: 0.1361, Entropy: 0.0000, Distance: 6.8064
Step 16: Loss: 0.1342, Entropy: 0.0000, Distance: 6.7108
Step 17: Loss: 0.1319, Entropy: 0.0000, Distance: 6.5935
Step 18: Loss: 0.1292, Entropy: 0.0000, Distance: 6.4582
Step 19: Loss: 0.1262, Entropy: 0.0000, Distance: 6.3083
Step 20: Loss: 0.1230, Entropy: 0.0000, Distance: 6.1468
Step 21: Loss: 0.1195, Entropy: 0.0000, Distance: 5.9766
Step 22: Loss: 0.1160, Entropy: 0.0000, Distance: 5.8001
Step 23: Loss: 0.1124, Entropy: 0.0000, Distance: 5.6198
Step 24: Loss: 0.1088, Entropy: 0.0000, Distance: 5.4377
Step 25: Loss: 0.1051, Entropy: 0.0000, Distance: 5.2557
Step 26: Loss: 0.1015, Entropy: 0.0000, Distance: 5.0754
Step 27: Loss: 0.0980, Entropy: 0.0000, Distance: 4.8985
Step 28: Loss: 0.0946, Entropy: 0.0000, Distance: 4.7262
Step 29: Loss: 0.0912, Entropy: 0.0000, Distance: 4.5598
Step 30: Loss: 0.0881, Entropy: 0.0001, Distance: 4.4002
Step 31: Loss: 0.0850, Entropy: 0.0001, Distance: 4.2485
Step 32: Loss: 0.0822, Entropy: 0.0001, Distance: 4.1055
Step 33: Loss: 0.0795, Entropy: 0.0001, Distance: 3.9717
Step 34: Loss: 0.0771, Entropy: 0.0001, Distance: 3.8476
Step 35: Loss: 0.0748, Entropy: 0.0001, Distance: 3.7334
Step 36: Loss: 0.0727, Entropy: 0.0001, Distance: 3.6291
Step 37: Loss: 0.0708, Entropy: 0.0002, Distance: 3.5342
Step 38: Loss: 0.0692, Entropy: 0.0002, Distance: 3.4482
Step 39: Loss: 0.0676, Entropy: 0.0002, Distance: 3.3703
Step 40: Loss: 0.0662, Entropy: 0.0003, Distance: 3.2997
Step 41: Loss: 0.0650, Entropy: 0.0003, Distance: 3.2356
Step 42: Loss: 0.0639, Entropy: 0.0003, Distance: 3.1771
Step 43: Loss: 0.0628, Entropy: 0.0004, Distance: 3.1233
Step 44: Loss: 0.0619, Entropy: 0.0004, Distance: 3.0736
Step 45: Loss: 0.0610, Entropy: 0.0005, Distance: 3.0270
Step 46: Loss: 0.0602, Entropy: 0.0005, Distance: 2.9829
Step 47: Loss: 0.0594, Entropy: 0.0006, Distance: 2.9405
Step 48: Loss: 0.0586, Entropy: 0.0006, Distance: 2.8991
Step 49: Loss: 0.0578, Entropy: 0.0007, Distance: 2.8584
Step 00: Loss: 0.9790, Entropy: 0.9790, Distance: 0.0000
Step 01: Loss: 0.2657, Entropy: 0.2337, Distance: 1.6000
Step 02: Loss: 0.0901, Entropy: 0.0325, Distance: 2.8828
Step 03: Loss: 0.0835, Entropy: 0.0062, Distance: 3.8685
Step 04: Loss: 0.0937, Entropy: 0.0017, Distance: 4.5995
Step 05: Loss: 0.1034, Entropy: 0.0006, Distance: 5.1383
Step 06: Loss: 0.1109, Entropy: 0.0003, Distance: 5.5297
Step 07: Loss: 0.1162, Entropy: 0.0001, Distance: 5.8049
Step 08: Loss: 0.1198, Entropy: 0.0001, Distance: 5.9865
Step 09: Loss: 0.1219, Entropy: 0.0001, Distance: 6.0920
Step 10: Loss: 0.1227, Entropy: 0.0000, Distance: 6.1350
Step 11: Loss: 0.1226, Entropy: 0.0000, Distance: 6.1265
Step 12: Loss: 0.1215, Entropy: 0.0000, Distance: 6.0759
Step 13: Loss: 0.1198, Entropy: 0.0000, Distance: 5.9911
Step 14: Loss: 0.1176, Entropy: 0.0000, Distance: 5.8786
Step 15: Loss: 0.1149, Entropy: 0.0000, Distance: 5.7443
Step 16: Loss: 0.1119, Entropy: 0.0000, Distance: 5.5936
Step 17: Loss: 0.1086, Entropy: 0.0000, Distance: 5.4310
Step 18: Loss: 0.1052, Entropy: 0.0000, Distance: 5.2606
Step 19: Loss: 0.1017, Entropy: 0.0000, Distance: 5.0862
Step 20: Loss: 0.0982, Entropy: 0.0000, Distance: 4.9105
Step 21: Loss: 0.0948, Entropy: 0.0000, Distance: 4.7363
Step 22: Loss: 0.0913, Entropy: 0.0000, Distance: 4.5657
Step 23: Loss: 0.0880, Entropy: 0.0000, Distance: 4.4007
Step 24: Loss: 0.0849, Entropy: 0.0000, Distance: 4.2426
Step 25: Loss: 0.0819, Entropy: 0.0000, Distance: 4.0926
Step 26: Loss: 0.0791, Entropy: 0.0001, Distance: 3.9516
Step 27: Loss: 0.0765, Entropy: 0.0001, Distance: 3.8201
Step 28: Loss: 0.0740, Entropy: 0.0001, Distance: 3.6986
Step 29: Loss: 0.0718, Entropy: 0.0001, Distance: 3.5875
Step 30: Loss: 0.0698, Entropy: 0.0001, Distance: 3.4866
Step 31: Loss: 0.0680, Entropy: 0.0001, Distance: 3.3956
Step 32: Loss: 0.0664, Entropy: 0.0001, Distance: 3.3141
Step 33: Loss: 0.0650, Entropy: 0.0001, Distance: 3.2411
Step 34: Loss: 0.0637, Entropy: 0.0002, Distance: 3.1756
Step 35: Loss: 0.0625, Entropy: 0.0002, Distance: 3.1166
Step 36: Loss: 0.0615, Entropy: 0.0002, Distance: 3.0629
Step 37: Loss: 0.0605, Entropy: 0.0002, Distance: 3.0132
Step 38: Loss: 0.0596, Entropy: 0.0003, Distance: 2.9663
Step 39: Loss: 0.0587, Entropy: 0.0003, Distance: 2.9210
Step 40: Loss: 0.0578, Entropy: 0.0003, Distance: 2.8762
Step 41: Loss: 0.0570, Entropy: 0.0003, Distance: 2.8313
Step 42: Loss: 0.0561, Entropy: 0.0004, Distance: 2.7858
Step 43: Loss: 0.0552, Entropy: 0.0004, Distance: 2.7395
Step 44: Loss: 0.0543, Entropy: 0.0004, Distance: 2.6925
Step 45: Loss: 0.0533, Entropy: 0.0004, Distance: 2.6448
Step 46: Loss: 0.0524, Entropy: 0.0005, Distance: 2.5966
Step 47: Loss: 0.0515, Entropy: 0.0005, Distance: 2.5479
Step 48: Loss: 0.0505, Entropy: 0.0005, Distance: 2.4988
Step 49: Loss: 0.0496, Entropy: 0.0006, Distance: 2.4497
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{test-new-clue_files/test-new-clue_33_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]

Class probabilities for last example:
Original (Class 8): [0.    0.    0.003 0.12  0.    0.007 0.    0.004 0.61
0.256]
Explained (Class 8): [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
    \end{Verbatim}


    % Add a bibliography block to the postdoc
    
    
    
\end{document}
